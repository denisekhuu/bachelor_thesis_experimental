{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1fe4f3d4-0a22-45ee-8666-ecfb51812149",
      "metadata": {
        "id": "1fe4f3d4-0a22-45ee-8666-ecfb51812149"
      },
      "source": [
        "# Poisoning Attack in Federated Learning Experiment 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.flush_and_unmount()\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2Vf2Mi6GhEG",
        "outputId": "ffbe419e-cc16-4d3a-d03e-ff3f94f9163c"
      },
      "id": "M2Vf2Mi6GhEG",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/Colab Notebooks')\n",
        "sys.path.append('/content/drive/My Drive/Colab Notebooks/federated_learning')"
      ],
      "metadata": {
        "id": "rvrHDJ6OGk-c"
      },
      "id": "rvrHDJ6OGk-c",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install shap"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9n3fTWy5KXBw",
        "outputId": "f032ed5f-d175-4dce-cdde-e4ae648449d0"
      },
      "id": "9n3fTWy5KXBw",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting shap\n",
            "  Downloading shap-0.41.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (569 kB)\n",
            "\u001b[K     |████████████████████████████████| 569 kB 23.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from shap) (1.21.6)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from shap) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4.25.0 in /usr/local/lib/python3.7/dist-packages (from shap) (4.64.0)\n",
            "Collecting slicer==0.0.7\n",
            "  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from shap) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from shap) (1.0.2)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.7/dist-packages (from shap) (21.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from shap) (1.3.5)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from shap) (0.51.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>20.9->shap) (3.0.9)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba->shap) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba->shap) (57.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->shap) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->shap) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->shap) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->shap) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->shap) (3.1.0)\n",
            "Installing collected packages: slicer, shap\n",
            "Successfully installed shap-0.41.0 slicer-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fffab25b-d49e-4c49-832a-f96723b48671",
      "metadata": {
        "id": "fffab25b-d49e-4c49-832a-f96723b48671"
      },
      "source": [
        "Purpose: \n",
        "- What is the performance loss induced through the different poisoning attack? \n",
        "- What is the performance of the global model without poisoning?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "466d7488-718e-4275-b3ca-ceb4bfc32f23",
      "metadata": {
        "id": "466d7488-718e-4275-b3ca-ceb4bfc32f23"
      },
      "outputs": [],
      "source": [
        "from federated_learning.utils import SHAPUtil, experiment_util\n",
        "from federated_learning import ClientPlane, Configuration, ObserverConfiguration\n",
        "from federated_learning.server import Server\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3350261c-a693-4ee1-aae2-3b1b68addad4",
      "metadata": {
        "id": "3350261c-a693-4ee1-aae2-3b1b68addad4"
      },
      "source": [
        "## Additional Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "ef2cd015-f2b1-4d07-a9c2-ecb49c38db25",
      "metadata": {
        "id": "ef2cd015-f2b1-4d07-a9c2-ecb49c38db25"
      },
      "outputs": [],
      "source": [
        "class Experiment():\n",
        "    def __init__(self, num_p_clients, from_label, to_label, natural_label ):\n",
        "        self.num_p_clients = num_p_clients\n",
        "        self.from_label = from_label\n",
        "        self.to_label = to_label\n",
        "        self.neutral_label = natural_label\n",
        "        self.accuracy = []\n",
        "        self.recall = {}\n",
        "        self.initialize_recall()\n",
        "\n",
        "    def initialize_recall(self):\n",
        "        self.recall[self.from_label] = []\n",
        "        self.recall[self.to_label] = []\n",
        "        self.recall[self.neutral_label] = []\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77c6b825-9314-449c-9f7a-8224e57baa31",
      "metadata": {
        "id": "77c6b825-9314-449c-9f7a-8224e57baa31"
      },
      "outputs": [],
      "source": [
        "experiments = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "e53cd9e1-7430-43c1-a6a2-be102463d227",
      "metadata": {
        "id": "e53cd9e1-7430-43c1-a6a2-be102463d227"
      },
      "outputs": [],
      "source": [
        "def add_round_to_experiment(experiment, recall, accuracy, from_label, to_label, neutral_label): \n",
        "    experiment.accuracy.append(accuracy)\n",
        "    experiment.recall[from_label].append(recall[from_label])\n",
        "    experiment.recall[to_label].append(recall[to_label])\n",
        "    experiment.recall[neutral_label].append(recall[neutral_label])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8600156e-91dd-4a11-a8aa-f0efda25abce",
      "metadata": {
        "tags": [],
        "id": "8600156e-91dd-4a11-a8aa-f0efda25abce"
      },
      "source": [
        "## Experiment 1.0: MNIST(5,4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "caf2c6d0-14e1-45e0-902c-b844823597f4",
      "metadata": {
        "tags": [],
        "id": "caf2c6d0-14e1-45e0-902c-b844823597f4"
      },
      "outputs": [],
      "source": [
        "from federated_learning.nets import MNISTCNN\n",
        "from federated_learning.dataset import MNISTDataset\n",
        "import os\n",
        "config = Configuration()\n",
        "config.TEMP = os.path.join('/content/drive/My Drive/Colab Notebooks/temp')\n",
        "config.FMNIST_DATASET_PATH = os.path.join('/content/data/fmnist')\n",
        "config.MNIST_DATASET_PATH = os.path.join('/content/data/fmnist')\n",
        "config.CIFAR10_DATASET_PATH = os.path.join('/content/data/fmnist')\n",
        "config.VM_URL = \"none\"\n",
        "config.FROM_LABEL = 5\n",
        "config.TO_LABEL = 4\n",
        "config.POISONED_CLIENTS = 0\n",
        "config.DATA_POISONING_PERCENTAGE = 1\n",
        "config.DATASET = MNISTDataset\n",
        "config.MODELNAME = config.MNIST_NAME\n",
        "config.NETWORK = MNISTCNN\n",
        "observer_config = ObserverConfiguration()\n",
        "observer_config.experiment_type = \"shap_fl_poisoned\"\n",
        "observer_config.experiment_id = 1\n",
        "observer_config.test = False\n",
        "observer_config.datasetObserverConfiguration = \"MNIST\"\n",
        "neutral_label = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "b4ce109f-9cf1-45ef-a893-4ebbe4d8d6a8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4ce109f-9cf1-45ef-a893-4ebbe4d8d6a8",
        "outputId": "f1af2de8-ea02-4ff9-e086-3b2a1ba078c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MNIST training data loaded.\n",
            "MNIST test data loaded.\n"
          ]
        }
      ],
      "source": [
        "data = config.DATASET(config)\n",
        "shap_util = SHAPUtil(data.test_dataloader) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "9ca9f211-36c6-49fc-a5ce-bec4420134b6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ca9f211-36c6-49fc-a5ce-bec4420134b6",
        "outputId": "3d247645-4888-4a91-e077-17e859a95aae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create 200 clients with dataset of size 300\n"
          ]
        }
      ],
      "source": [
        "server = Server(config, observer_config,data.train_dataloader, data.test_dataloader, shap_util)\n",
        "client_plane = ClientPlane(config, observer_config, data, shap_util)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2eef9ecf-7e5a-4c3d-a06c-64ba662b68bf",
      "metadata": {
        "scrolled": true,
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2eef9ecf-7e5a-4c3d-a06c-64ba662b68bf",
        "outputId": "b38a799f-7a8d-4148-c893-83d3f939d797"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load default model successfully\n",
            "No poisoning due to 0. poisoned clients\n",
            "\n",
            "Test set: Average loss: 0.0023, Accuracy: 636/10000 (6%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 7977/10000 (80%)\n",
            "\n",
            "Round 10 finished\n",
            "\n",
            "Test set: Average loss: 0.0005, Accuracy: 9080/10000 (91%)\n",
            "\n",
            "Round 20 finished\n",
            "\n",
            "Test set: Average loss: 0.0004, Accuracy: 9271/10000 (93%)\n",
            "\n",
            "Round 30 finished\n",
            "\n",
            "Test set: Average loss: 0.0003, Accuracy: 9382/10000 (94%)\n",
            "\n",
            "Round 40 finished\n",
            "Model aggregation in round 50 was successful\n",
            "\n",
            "Test set: Average loss: 0.0003, Accuracy: 9460/10000 (95%)\n",
            "\n",
            "Round 50 finished\n",
            "\n",
            "Test set: Average loss: 0.0002, Accuracy: 9516/10000 (95%)\n",
            "\n",
            "Round 60 finished\n",
            "\n",
            "Test set: Average loss: 0.0002, Accuracy: 9557/10000 (96%)\n",
            "\n",
            "Round 70 finished\n",
            "\n",
            "Test set: Average loss: 0.0002, Accuracy: 9560/10000 (96%)\n",
            "\n",
            "Round 80 finished\n",
            "\n",
            "Test set: Average loss: 0.0002, Accuracy: 9602/10000 (96%)\n",
            "\n",
            "Round 90 finished\n",
            "Model aggregation in round 100 was successful\n",
            "Train Epoch: 100 [0/300 (0%)]\tLoss: 0.013946\n",
            "Train Epoch: 100 [10/300 (3%)]\tLoss: 0.090890\n",
            "Train Epoch: 100 [20/300 (7%)]\tLoss: 0.070434\n",
            "Train Epoch: 100 [30/300 (10%)]\tLoss: 0.133586\n",
            "Train Epoch: 100 [40/300 (13%)]\tLoss: 0.035561\n",
            "Train Epoch: 100 [50/300 (17%)]\tLoss: 0.070014\n",
            "Train Epoch: 100 [60/300 (20%)]\tLoss: 0.262101\n",
            "Train Epoch: 100 [70/300 (23%)]\tLoss: 0.146407\n",
            "Train Epoch: 100 [80/300 (27%)]\tLoss: 0.137443\n",
            "Train Epoch: 100 [90/300 (30%)]\tLoss: 0.020015\n",
            "Train Epoch: 100 [100/300 (33%)]\tLoss: 0.271870\n",
            "Train Epoch: 100 [110/300 (37%)]\tLoss: 0.016045\n",
            "Train Epoch: 100 [120/300 (40%)]\tLoss: 0.186899\n",
            "Train Epoch: 100 [130/300 (43%)]\tLoss: 0.100326\n",
            "Train Epoch: 100 [140/300 (47%)]\tLoss: 0.058118\n",
            "Train Epoch: 100 [150/300 (50%)]\tLoss: 0.441944\n",
            "Train Epoch: 100 [160/300 (53%)]\tLoss: 0.026473\n",
            "Train Epoch: 100 [170/300 (57%)]\tLoss: 0.147633\n",
            "Train Epoch: 100 [180/300 (60%)]\tLoss: 0.237369\n",
            "Train Epoch: 100 [190/300 (63%)]\tLoss: 0.117408\n",
            "Train Epoch: 100 [200/300 (67%)]\tLoss: 0.644127\n",
            "Train Epoch: 100 [210/300 (70%)]\tLoss: 0.382140\n",
            "Train Epoch: 100 [220/300 (73%)]\tLoss: 0.019622\n",
            "Train Epoch: 100 [230/300 (77%)]\tLoss: 0.248026\n",
            "Train Epoch: 100 [240/300 (80%)]\tLoss: 0.880010\n",
            "Train Epoch: 100 [250/300 (83%)]\tLoss: 0.016883\n",
            "Train Epoch: 100 [260/300 (87%)]\tLoss: 0.128669\n",
            "Train Epoch: 100 [270/300 (90%)]\tLoss: 0.125359\n",
            "Train Epoch: 100 [280/300 (93%)]\tLoss: 0.291313\n",
            "Train Epoch: 100 [290/300 (97%)]\tLoss: 0.044324\n",
            "Train Epoch: 100 [0/300 (0%)]\tLoss: 0.141295\n",
            "Train Epoch: 100 [10/300 (3%)]\tLoss: 0.307358\n",
            "Train Epoch: 100 [20/300 (7%)]\tLoss: 0.191685\n",
            "Train Epoch: 100 [30/300 (10%)]\tLoss: 0.976301\n",
            "Train Epoch: 100 [40/300 (13%)]\tLoss: 0.257473\n",
            "Train Epoch: 100 [50/300 (17%)]\tLoss: 0.491580\n",
            "Train Epoch: 100 [60/300 (20%)]\tLoss: 0.645194\n",
            "Train Epoch: 100 [70/300 (23%)]\tLoss: 0.231518\n",
            "Train Epoch: 100 [80/300 (27%)]\tLoss: 0.357522\n",
            "Train Epoch: 100 [90/300 (30%)]\tLoss: 0.145287\n",
            "Train Epoch: 100 [100/300 (33%)]\tLoss: 0.721397\n",
            "Train Epoch: 100 [110/300 (37%)]\tLoss: 0.430709\n",
            "Train Epoch: 100 [120/300 (40%)]\tLoss: 0.399013\n",
            "Train Epoch: 100 [130/300 (43%)]\tLoss: 0.073080\n",
            "Train Epoch: 100 [140/300 (47%)]\tLoss: 0.114218\n",
            "Train Epoch: 100 [150/300 (50%)]\tLoss: 0.169395\n",
            "Train Epoch: 100 [160/300 (53%)]\tLoss: 0.229973\n",
            "Train Epoch: 100 [170/300 (57%)]\tLoss: 0.550502\n",
            "Train Epoch: 100 [180/300 (60%)]\tLoss: 0.669741\n",
            "Train Epoch: 100 [190/300 (63%)]\tLoss: 0.468148\n",
            "Train Epoch: 100 [200/300 (67%)]\tLoss: 0.492855\n",
            "Train Epoch: 100 [210/300 (70%)]\tLoss: 0.422083\n",
            "Train Epoch: 100 [220/300 (73%)]\tLoss: 0.410418\n",
            "Train Epoch: 100 [230/300 (77%)]\tLoss: 0.377635\n",
            "Train Epoch: 100 [240/300 (80%)]\tLoss: 0.292052\n",
            "Train Epoch: 100 [250/300 (83%)]\tLoss: 0.466190\n",
            "Train Epoch: 100 [260/300 (87%)]\tLoss: 0.481359\n",
            "Train Epoch: 100 [270/300 (90%)]\tLoss: 0.527979\n",
            "Train Epoch: 100 [280/300 (93%)]\tLoss: 0.478455\n",
            "Train Epoch: 100 [290/300 (97%)]\tLoss: 0.372633\n",
            "Train Epoch: 100 [0/300 (0%)]\tLoss: 0.143604\n",
            "Train Epoch: 100 [10/300 (3%)]\tLoss: 0.245106\n",
            "Train Epoch: 100 [20/300 (7%)]\tLoss: 0.023411\n",
            "Train Epoch: 100 [30/300 (10%)]\tLoss: 0.125150\n",
            "Train Epoch: 100 [40/300 (13%)]\tLoss: 0.162554\n",
            "Train Epoch: 100 [50/300 (17%)]\tLoss: 0.071217\n",
            "Train Epoch: 100 [60/300 (20%)]\tLoss: 0.122204\n",
            "Train Epoch: 100 [70/300 (23%)]\tLoss: 0.520096\n",
            "Train Epoch: 100 [80/300 (27%)]\tLoss: 0.035038\n",
            "Train Epoch: 100 [90/300 (30%)]\tLoss: 0.061029\n",
            "Train Epoch: 100 [100/300 (33%)]\tLoss: 0.105848\n",
            "Train Epoch: 100 [110/300 (37%)]\tLoss: 0.210789\n",
            "Train Epoch: 100 [120/300 (40%)]\tLoss: 0.242942\n",
            "Train Epoch: 100 [130/300 (43%)]\tLoss: 0.129052\n",
            "Train Epoch: 100 [140/300 (47%)]\tLoss: 0.131957\n",
            "Train Epoch: 100 [150/300 (50%)]\tLoss: 0.188886\n",
            "Train Epoch: 100 [160/300 (53%)]\tLoss: 0.269343\n",
            "Train Epoch: 100 [170/300 (57%)]\tLoss: 0.251776\n",
            "Train Epoch: 100 [180/300 (60%)]\tLoss: 0.302767\n",
            "Train Epoch: 100 [190/300 (63%)]\tLoss: 0.019704\n",
            "Train Epoch: 100 [200/300 (67%)]\tLoss: 0.000970\n",
            "Train Epoch: 100 [210/300 (70%)]\tLoss: 0.137912\n",
            "Train Epoch: 100 [220/300 (73%)]\tLoss: 0.192478\n",
            "Train Epoch: 100 [230/300 (77%)]\tLoss: 0.340428\n",
            "Train Epoch: 100 [240/300 (80%)]\tLoss: 0.091387\n",
            "Train Epoch: 100 [250/300 (83%)]\tLoss: 0.426915\n",
            "Train Epoch: 100 [260/300 (87%)]\tLoss: 0.062077\n",
            "Train Epoch: 100 [270/300 (90%)]\tLoss: 0.543073\n",
            "Train Epoch: 100 [280/300 (93%)]\tLoss: 0.066873\n",
            "Train Epoch: 100 [290/300 (97%)]\tLoss: 0.153883\n",
            "Train Epoch: 100 [0/300 (0%)]\tLoss: 0.265015\n",
            "Train Epoch: 100 [10/300 (3%)]\tLoss: 0.408283\n",
            "Train Epoch: 100 [20/300 (7%)]\tLoss: 0.636741\n",
            "Train Epoch: 100 [30/300 (10%)]\tLoss: 0.050356\n",
            "Train Epoch: 100 [40/300 (13%)]\tLoss: 0.355311\n",
            "Train Epoch: 100 [50/300 (17%)]\tLoss: 0.389234\n",
            "Train Epoch: 100 [60/300 (20%)]\tLoss: 0.341168\n",
            "Train Epoch: 100 [70/300 (23%)]\tLoss: 0.109470\n",
            "Train Epoch: 100 [80/300 (27%)]\tLoss: 0.135137\n",
            "Train Epoch: 100 [90/300 (30%)]\tLoss: 0.973429\n",
            "Train Epoch: 100 [100/300 (33%)]\tLoss: 0.122119\n",
            "Train Epoch: 100 [110/300 (37%)]\tLoss: 0.008662\n",
            "Train Epoch: 100 [120/300 (40%)]\tLoss: 0.881233\n",
            "Train Epoch: 100 [130/300 (43%)]\tLoss: 0.047733\n",
            "Train Epoch: 100 [140/300 (47%)]\tLoss: 0.523882\n",
            "Train Epoch: 100 [150/300 (50%)]\tLoss: 0.237735\n",
            "Train Epoch: 100 [160/300 (53%)]\tLoss: 0.507373\n",
            "Train Epoch: 100 [170/300 (57%)]\tLoss: 1.089456\n",
            "Train Epoch: 100 [180/300 (60%)]\tLoss: 0.184952\n",
            "Train Epoch: 100 [190/300 (63%)]\tLoss: 0.212795\n",
            "Train Epoch: 100 [200/300 (67%)]\tLoss: 0.078227\n",
            "Train Epoch: 100 [210/300 (70%)]\tLoss: 0.291413\n",
            "Train Epoch: 100 [220/300 (73%)]\tLoss: 0.396458\n",
            "Train Epoch: 100 [230/300 (77%)]\tLoss: 0.407400\n",
            "Train Epoch: 100 [240/300 (80%)]\tLoss: 0.171299\n",
            "Train Epoch: 100 [250/300 (83%)]\tLoss: 0.067843\n",
            "Train Epoch: 100 [260/300 (87%)]\tLoss: 0.159389\n",
            "Train Epoch: 100 [270/300 (90%)]\tLoss: 0.024437\n",
            "Train Epoch: 100 [280/300 (93%)]\tLoss: 0.222723\n",
            "Train Epoch: 100 [290/300 (97%)]\tLoss: 0.154377\n",
            "Train Epoch: 100 [0/300 (0%)]\tLoss: 0.297012\n",
            "Train Epoch: 100 [10/300 (3%)]\tLoss: 0.040160\n",
            "Train Epoch: 100 [20/300 (7%)]\tLoss: 0.008428\n",
            "Train Epoch: 100 [30/300 (10%)]\tLoss: 0.012954\n",
            "Train Epoch: 100 [40/300 (13%)]\tLoss: 0.062560\n",
            "Train Epoch: 100 [50/300 (17%)]\tLoss: 0.134029\n",
            "Train Epoch: 100 [60/300 (20%)]\tLoss: 0.027774\n",
            "Train Epoch: 100 [70/300 (23%)]\tLoss: 0.180929\n",
            "Train Epoch: 100 [80/300 (27%)]\tLoss: 0.230405\n",
            "Train Epoch: 100 [90/300 (30%)]\tLoss: 0.131192\n",
            "Train Epoch: 100 [100/300 (33%)]\tLoss: 0.020904\n",
            "Train Epoch: 100 [110/300 (37%)]\tLoss: 0.125054\n",
            "Train Epoch: 100 [120/300 (40%)]\tLoss: 0.036700\n",
            "Train Epoch: 100 [130/300 (43%)]\tLoss: 0.323905\n",
            "Train Epoch: 100 [140/300 (47%)]\tLoss: 0.091142\n",
            "Train Epoch: 100 [150/300 (50%)]\tLoss: 0.138712\n",
            "Train Epoch: 100 [160/300 (53%)]\tLoss: 1.651537\n",
            "Train Epoch: 100 [170/300 (57%)]\tLoss: 0.059742\n",
            "Train Epoch: 100 [180/300 (60%)]\tLoss: 0.022212\n",
            "Train Epoch: 100 [190/300 (63%)]\tLoss: 0.181499\n",
            "Train Epoch: 100 [200/300 (67%)]\tLoss: 0.104598\n",
            "Train Epoch: 100 [210/300 (70%)]\tLoss: 0.056989\n",
            "Train Epoch: 100 [220/300 (73%)]\tLoss: 0.092119\n",
            "Train Epoch: 100 [230/300 (77%)]\tLoss: 0.281015\n",
            "Train Epoch: 100 [240/300 (80%)]\tLoss: 0.162296\n",
            "Train Epoch: 100 [250/300 (83%)]\tLoss: 0.030679\n",
            "Train Epoch: 100 [260/300 (87%)]\tLoss: 0.084105\n",
            "Train Epoch: 100 [270/300 (90%)]\tLoss: 0.052448\n",
            "Train Epoch: 100 [280/300 (93%)]\tLoss: 0.141451\n",
            "Train Epoch: 100 [290/300 (97%)]\tLoss: 1.170057\n",
            "\n",
            "Test set: Average loss: 0.0001, Accuracy: 9606/10000 (96%)\n",
            "\n",
            "Round 100 finished\n",
            "\n",
            "Test set: Average loss: 0.0001, Accuracy: 9629/10000 (96%)\n",
            "\n",
            "Round 110 finished\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import copy\n",
        "for num_p_clients in [0, 10, 25, 50,75, 100, 200]:\n",
        "    client_plane.reset_default_client_nets()\n",
        "    server.reset_to_default_net()\n",
        "    client_plane.reset_poisoning_attack()\n",
        "    config.POISONED_CLIENTS = num_p_clients\n",
        "    experiment = Experiment(num_p_clients, config.FROM_LABEL, config.TO_LABEL, neutral_label)\n",
        "    experiment_util.update_configs(client_plane, server, config, observer_config)\n",
        "    client_plane.poison_clients()\n",
        "    server.test()\n",
        "    recall, precision, accuracy = server.analize_test()\n",
        "    add_round_to_experiment(experiment, recall, accuracy, config.FROM_LABEL, config.TO_LABEL, neutral_label)\n",
        "    for i in range(200):\n",
        "        experiment_util.set_rounds(client_plane, server, i+1)\n",
        "        experiment_util.run_round(client_plane, server, i+1)\n",
        "        if (i+1)%10 == 0:\n",
        "            server.test()\n",
        "            recall, precision, accuracy = server.analize_test()\n",
        "            add_round_to_experiment(experiment, recall, accuracy, config.FROM_LABEL, config.TO_LABEL, neutral_label)\n",
        "            print(\"Round {} finished\".format(i+1))\n",
        "    print(experiment.accuracy)\n",
        "    print(experiment.recall[config.FROM_LABEL])\n",
        "    print(experiment.recall[config.TO_LABEL])\n",
        "    print(experiment.recall[natural_label])\n",
        "    experiments.append(copy.deepcopy(experiment))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ca65987-118d-45df-974e-6d0248b360b0",
      "metadata": {
        "scrolled": true,
        "tags": [],
        "id": "3ca65987-118d-45df-974e-6d0248b360b0"
      },
      "outputs": [],
      "source": [
        "for e in experiments: \n",
        "    print(e.accuracyracy)\n",
        "    print(e.recall[config.FROM_LABEL])\n",
        "    print(e.recall[config.TO_LABEL])\n",
        "    print(e.recall[neutral_label])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6f621ea-1b3a-4c2a-9ad7-03ec54c9ed46",
      "metadata": {
        "id": "a6f621ea-1b3a-4c2a-9ad7-03ec54c9ed46"
      },
      "source": [
        "# Experiment 1.0: Fashion MNIST(5,4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "0eeb61a0-2d44-4d93-be81-7e23b6fd8d6b",
      "metadata": {
        "id": "0eeb61a0-2d44-4d93-be81-7e23b6fd8d6b"
      },
      "outputs": [],
      "source": [
        "from federated_learning.nets import FMNISTCNN\n",
        "from federated_learning.dataset import FMNISTDataset\n",
        "config = Configuration()\n",
        "config.FROM_LABEL = 5\n",
        "config.TO_LABEL = 4\n",
        "config.POISONED_CLIENTS = 0\n",
        "config.DATA_POISONING_PERCENTAGE = 1\n",
        "config.DATASET = FMNISTDataset\n",
        "config.MODELNAME = config.FMNIST_NAME\n",
        "config.NETWORK = FMNISTCNN\n",
        "observer_config = ObserverConfiguration()\n",
        "observer_config.experiment_type = \"shap_fl_poisoned\"\n",
        "observer_config.experiment_id = 1\n",
        "observer_config.test = False\n",
        "observer_config.dataset = \"FMNIST\"\n",
        "neutral_label = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "8a322c77-87bf-45e1-819e-35c2e5dd799a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "8a322c77-87bf-45e1-819e-35c2e5dd799a",
        "outputId": "20d69689-544a-4a3e-f3bb-83e8dcebee61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FashionMnist training data loaded.\n",
            "FashionMnist training data loaded.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-ffac457a252a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATASET\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mshap_util\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSHAPUtil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mserver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mServer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobserver_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshap_util\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mclient_plane\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClientPlane\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobserver_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshap_util\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mexperiments_fmnist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/Colab Notebooks/federated_learning/server/server.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config, observer_config, train_dataloader, test_dataloader, shap_util)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobserver_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshap_util\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mServer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobserver_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshap_util\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_model_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTEMP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'models'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"{}.model\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMODELNAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobserver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mServerObserver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobserver_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/Colab Notebooks/federated_learning/utils/cnn_handler.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config, observer_config, train_dataloader, test_dataloader, shap_util)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobserver_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobserver_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshap_util\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshap_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_default_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrounds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/Colab Notebooks/federated_learning/utils/cnn_handler.py\u001b[0m in \u001b[0;36mload_default_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Couldn't load model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Could not find model: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_model_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Server' object has no attribute 'default_model_path'"
          ]
        }
      ],
      "source": [
        "data = config.DATASET(config)\n",
        "shap_util = SHAPUtil(data.test_dataloader) \n",
        "server = Server(config, observer_config,data.train_dataloader, data.test_dataloader, shap_util)\n",
        "client_plane = ClientPlane(config, observer_config, data, shap_util)\n",
        "experiments_fmnist = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0091bc85-8f15-465a-87f3-ba7bcebd212b",
      "metadata": {
        "id": "0091bc85-8f15-465a-87f3-ba7bcebd212b",
        "outputId": "9e35c6b6-7dbe-487a-e001-bc2eb0ceada2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load default model successfully\n",
            "No poisoning due to 0. poisoned clients\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0023, Accuracy: 1252/10000 (13%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0005, Accuracy: 8162/10000 (82%)\n",
            "\n",
            "Round 10 finished\n",
            "\n",
            "Test set: Average loss: 0.0005, Accuracy: 8411/10000 (84%)\n",
            "\n",
            "Round 20 finished\n",
            "\n",
            "Test set: Average loss: 0.0004, Accuracy: 8540/10000 (85%)\n",
            "\n",
            "Round 30 finished\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import copy\n",
        "for num_p_clients in [0, 10, 25, 50, 75, 100, 200]:\n",
        "    client_plane.reset_default_client_nets()\n",
        "    server.reset_to_default_net()\n",
        "    client_plane.reset_poisoning_attack()\n",
        "    config.POISONED_CLIENTS = num_p_clients\n",
        "    experiment = Experiment(num_p_clients, config.FROM_LABEL, config.TO_LABEL, neutral_label)\n",
        "    experiment_util.update_configs(client_plane, server, config, observer_config)\n",
        "    client_plane.poison_clients()\n",
        "    server.test()\n",
        "    recall, precision, accuracy = server.analize_test()\n",
        "    add_round_to_experiment(experiment, recall, accuracy, config.FROM_LABEL, config.TO_LABEL, neutral_label)\n",
        "    for i in range(200):\n",
        "        experiment_util.set_rounds(client_plane, server, i+1)\n",
        "        experiment_util.run_round(client_plane, server, i+1)\n",
        "        if (i+1)%10 == 0:\n",
        "            server.test()\n",
        "            recall, precision, accuracy = server.analize_test()\n",
        "            add_round_to_experiment(experiment, recall, accuracy, config.FROM_LABEL, config.TO_LABEL, neutral_label)\n",
        "            print(\"Round {} finished\".format(i+1))\n",
        "    print(experiment.accuracy)\n",
        "    print(experiment.recall[config.FROM_LABEL])\n",
        "    print(experiment.recall[config.TO_LABEL])\n",
        "    print(experiment.recall[natural_label])\n",
        "    experiments_fmnist.append(copy.deepcopy(experiment))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "name": "poisoning_attack_experiment_1.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}