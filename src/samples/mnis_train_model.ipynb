{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d91c5a86-2173-4938-b072-60b6b688e75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from federated_learning.dataloader import MNISTDataloader\n",
    "from federated_learning.configuration import Configuration\n",
    "import torch \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4f3037c-68f9-4a6d-af05-97b8aba74f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2a6f3d4e-5db9-4b39-80ee-23b0429a2f57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fb10805f350>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configuration \n",
    "\n",
    "n_epochs = 3\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 10\n",
    "\n",
    "random_seed = 1\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2e6d65b2-1ccf-444b-8bd8-3646431804cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST training loader loaded.\n",
      "MNIST test loader loaded.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 28, 28])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = Configuration()\n",
    "mnist = MNISTDataloader(config)\n",
    "examples = enumerate(mnist.train_dataloader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "example_data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cfbc5dde-946d-4eb7-912c-f795032455f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "    plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b0095f-268d-4547-a439-0db4b9dd722c",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbdcea48-257a-4b31-8f64-85c8f56fa051",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "93547285-24f5-4945-91da-19242a7e1808",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c0c8f6f4-dcd0-4ecf-acf3-33d05518a22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "310f1903-285c-4320-ad7c-efb84f65649c",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Net()\n",
    "optimizer = optim.SGD(network.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "10292430-56cb-4518-9d0e-022c75e60d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_counter = [i*len(mnist.train_dataloader.dataset) for i in range(n_epochs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9d179f4d-4d8e-4c25-8437-591f9773fbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Test Funktions\n",
    "def train(epoch):\n",
    "    network.train()\n",
    "    for batch_idx, (data, target) in enumerate(mnist.train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        output = network(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(epoch, batch_idx * len(data), len(mnist.train_dataloader.dataset),100. * batch_idx / len(mnist.train_dataloader), loss.item()))\n",
    "            train_losses.append(loss.item())\n",
    "            train_counter.append((batch_idx*64) + ((epoch-1)*len(mnist.train_dataloader.dataset)))\n",
    "            torch.save(network.state_dict(), './results/model.pth')\n",
    "            torch.save(optimizer.state_dict(), './results/optimizer.pth')\n",
    "\n",
    "def test():\n",
    "    network.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in mnist.test_dataloader:\n",
    "            output = network(data)\n",
    "            test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "    test_loss /= len(mnist.test_dataloader.dataset)\n",
    "    test_losses.append(test_loss)\n",
    "    print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(test_loss, correct, len(mnist.test_dataloader.dataset), 100. * correct / len(mnist.test_dataloader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cd299bbf-63fd-40af-a08e-42e931300747",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4776/161431047.py:17: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.1041, Accuracy: 9666/10000 (97%)\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.193441\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 0.171581\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 0.321164\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 0.408518\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 0.230788\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 0.137324\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 0.304410\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 0.466659\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 0.423950\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 0.216544\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.325618\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 0.164347\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 0.159622\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 0.294066\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 0.150458\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.402324\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.609523\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 0.191997\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 0.354672\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 0.302242\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.212895\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 0.099530\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.257699\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 0.401065\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.308624\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.378977\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.353210\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.171199\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.164103\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.267498\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.540106\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.224305\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.184422\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.334513\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.148327\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.177150\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.267674\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.511841\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.092224\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.322218\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.160146\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.197652\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.193572\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.170045\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.358898\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.183886\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.272944\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.345075\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.253588\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.362019\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.346292\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.159845\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.241973\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.153044\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.191267\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.283976\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.238142\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.198833\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.278954\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.255056\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.215730\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.123482\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.148687\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.150713\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.269609\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.242962\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.221101\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.398213\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.303861\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.311777\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.515286\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.394924\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.315941\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.313793\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.383808\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.291128\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.236626\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.223002\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.200324\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.106254\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.314801\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.201524\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.093351\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.269016\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.094615\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.126501\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.289528\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.382424\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.298391\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.096276\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.449239\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.106183\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.049481\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.044393\n",
      "\n",
      "Test set: Avg. loss: 0.0929, Accuracy: 9699/10000 (97%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.198146\n",
      "Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.276644\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.236425\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.159088\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.233190\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.140511\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.114187\n",
      "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.205101\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.442365\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.320972\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.254008\n",
      "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.154405\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.317240\n",
      "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.132785\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.242933\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.358236\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.512482\n",
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.256576\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.244924\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.361965\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.215142\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.166731\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.277689\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.502758\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.230753\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.444697\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.343884\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.187560\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.163163\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.330355\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.185195\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.232305\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.126961\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.345719\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.109643\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.105944\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.248843\n",
      "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.401779\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.221794\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.293194\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.282477\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.240230\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.290551\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.384651\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.254526\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.203902\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.154910\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.419718\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.305204\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.357655\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.211796\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.289090\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.108956\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.100258\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.133709\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.287725\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.276446\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.404006\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.282286\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.339251\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.220954\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.041146\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.141099\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.110136\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.404282\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.267971\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.170619\n",
      "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.245407\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.338371\n",
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.238270\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.424432\n",
      "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.457395\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.243363\n",
      "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.268472\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.265074\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.228090\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.248549\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.109121\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.393300\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.216228\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.424001\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.283233\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.066889\n",
      "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.271025\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.128061\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.191058\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.191488\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.324185\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.309191\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.194985\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.470779\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.178408\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.041190\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.164469\n",
      "\n",
      "Test set: Avg. loss: 0.0898, Accuracy: 9724/10000 (97%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.175164\n",
      "Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.234664\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.332308\n",
      "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.137613\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.147847\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.233382\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.089748\n",
      "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.208635\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.373341\n",
      "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.390653\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.302381\n",
      "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.145830\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.144715\n",
      "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.192928\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.245416\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.304136\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.686162\n",
      "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.192193\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.351747\n",
      "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.236301\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.210212\n",
      "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.166425\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.193362\n",
      "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.308954\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.246614\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.510684\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.394179\n",
      "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.148792\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.074873\n",
      "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.259110\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.261599\n",
      "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.218450\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.106075\n",
      "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.249487\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.134754\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.175203\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.216454\n",
      "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.275504\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.101429\n",
      "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.140851\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.158933\n",
      "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.097744\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.347374\n",
      "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.360987\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.224715\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.182569\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.167827\n",
      "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.169709\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.234745\n",
      "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.370904\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.171917\n",
      "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.156222\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.339570\n",
      "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.102945\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.199005\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.327368\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.129552\n",
      "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.200106\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.253971\n",
      "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.335371\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.132345\n",
      "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.183960\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.177794\n",
      "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.104829\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.272757\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.207286\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.121237\n",
      "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.455314\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.194451\n",
      "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.225717\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.287633\n",
      "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.363162\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.276418\n",
      "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.363043\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.354058\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.170302\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.183780\n",
      "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.163134\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.260170\n",
      "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.189660\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.302457\n",
      "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.169547\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.088275\n",
      "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 0.205304\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.193209\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.107003\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.218261\n",
      "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.329080\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.176075\n",
      "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.160879\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.290751\n",
      "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.115723\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.053266\n",
      "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.212104\n",
      "\n",
      "Test set: Avg. loss: 0.0836, Accuracy: 9730/10000 (97%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test()\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
