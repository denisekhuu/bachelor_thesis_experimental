{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d91c5a86-2173-4938-b072-60b6b688e75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from federated_learning.dataloader import CIFAR10Dataloader\n",
    "from federated_learning.configuration import Configuration\n",
    "import torch \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4f3037c-68f9-4a6d-af05-97b8aba74f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a6f3d4e-5db9-4b39-80ee-23b0429a2f57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f9af0016f30>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configuration \n",
    "\n",
    "n_epochs = 3\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 10\n",
    "device = torch.device('cpu')\n",
    "random_seed = 1\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e6d65b2-1ccf-444b-8bd8-3646431804cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "CIFAR10 training loader loaded.\n",
      "Files already downloaded and verified\n",
      "CIFAR10 test loader loaded.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 3, 32, 32])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = Configuration()\n",
    "cifar = CIFAR10Dataloader(config)\n",
    "examples = enumerate(cifar.test_dataloader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "example_data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbc5dde-946d-4eb7-912c-f795032455f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "    plt.title(\"Ground Truth: {}\".format(cifar.labels[example_targets[i]]))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b0095f-268d-4547-a439-0db4b9dd722c",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbdcea48-257a-4b31-8f64-85c8f56fa051",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "93547285-24f5-4945-91da-19242a7e1808",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c0c8f6f4-dcd0-4ecf-acf3-33d05518a22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10CNN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CIFAR10CNN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.conv4 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.conv5 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(128)\n",
    "        self.conv6 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.bn6 = nn.BatchNorm2d(128)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.bn1(F.relu(self.conv1(x)))\n",
    "        x = self.bn2(F.relu(self.conv2(x)))\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.bn3(F.relu(self.conv3(x)))\n",
    "        x = self.bn4(F.relu(self.conv4(x)))\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = self.bn5(F.relu(self.conv5(x)))\n",
    "        x = self.bn6(F.relu(self.conv6(x)))\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        x = x.view(-1, 128 * 4 * 4)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = F.softmax(self.fc2(x))\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "310f1903-285c-4320-ad7c-efb84f65649c",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = CIFAR10CNN()\n",
    "optimizer = optim.SGD(network.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "10292430-56cb-4518-9d0e-022c75e60d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_counter = [i*len(cifar.train_dataloader.dataset) for i in range(n_epochs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9d179f4d-4d8e-4c25-8437-591f9773fbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Test Funktions\n",
    "def train(epoch):\n",
    "    network.train()\n",
    "    for batch_idx, (data, target) in enumerate(cifar.train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        output = network(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(epoch, batch_idx * len(data), len(cifar.train_dataloader.dataset),100. * batch_idx / len(cifar.train_dataloader), loss.item()))\n",
    "            train_losses.append(loss.item())\n",
    "            train_counter.append((batch_idx*64) + ((epoch-1)*len(cifar.train_dataloader.dataset)))\n",
    "            torch.save(network.state_dict(), './results/model.pth')\n",
    "            torch.save(optimizer.state_dict(), './results/optimizer.pth')\n",
    "\n",
    "def test():\n",
    "    network.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in cifar.test_dataloader:\n",
    "            output = network(data)\n",
    "            test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "    test_loss /= len(cifar.test_dataloader.dataset)\n",
    "    test_losses.append(test_loss)\n",
    "    print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(test_loss, correct, len(cifar.test_dataloader.dataset), 100. * correct / len(cifar.test_dataloader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cd299bbf-63fd-40af-a08e-42e931300747",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7896/3936406854.py:43: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = F.softmax(self.fc2(x))\n",
      "/opt/conda/lib/python3.9/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: -0.1000, Accuracy: 1000/10000 (10%)\n",
      "\n",
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 2.303483\n",
      "Train Epoch: 1 [640/50000 (1%)]\tLoss: 2.293258\n",
      "Train Epoch: 1 [1280/50000 (3%)]\tLoss: 2.274359\n",
      "Train Epoch: 1 [1920/50000 (4%)]\tLoss: 2.232622\n",
      "Train Epoch: 1 [2560/50000 (5%)]\tLoss: 2.220014\n",
      "Train Epoch: 1 [3200/50000 (6%)]\tLoss: 2.176952\n",
      "Train Epoch: 1 [3840/50000 (8%)]\tLoss: 2.168366\n",
      "Train Epoch: 1 [4480/50000 (9%)]\tLoss: 2.116184\n",
      "Train Epoch: 1 [5120/50000 (10%)]\tLoss: 2.139556\n",
      "Train Epoch: 1 [5760/50000 (12%)]\tLoss: 2.150638\n",
      "Train Epoch: 1 [6400/50000 (13%)]\tLoss: 2.080331\n",
      "Train Epoch: 1 [7040/50000 (14%)]\tLoss: 2.113095\n",
      "Train Epoch: 1 [7680/50000 (15%)]\tLoss: 2.164206\n",
      "Train Epoch: 1 [8320/50000 (17%)]\tLoss: 2.071815\n",
      "Train Epoch: 1 [8960/50000 (18%)]\tLoss: 2.033385\n",
      "Train Epoch: 1 [9600/50000 (19%)]\tLoss: 2.026993\n",
      "Train Epoch: 1 [10240/50000 (20%)]\tLoss: 2.002153\n",
      "Train Epoch: 1 [10880/50000 (22%)]\tLoss: 2.048242\n",
      "Train Epoch: 1 [11520/50000 (23%)]\tLoss: 1.997269\n",
      "Train Epoch: 1 [12160/50000 (24%)]\tLoss: 2.062496\n",
      "Train Epoch: 1 [12800/50000 (26%)]\tLoss: 2.044229\n",
      "Train Epoch: 1 [13440/50000 (27%)]\tLoss: 1.983235\n",
      "Train Epoch: 1 [14080/50000 (28%)]\tLoss: 2.062595\n",
      "Train Epoch: 1 [14720/50000 (29%)]\tLoss: 1.965667\n",
      "Train Epoch: 1 [15360/50000 (31%)]\tLoss: 2.125969\n",
      "Train Epoch: 1 [16000/50000 (32%)]\tLoss: 1.937813\n",
      "Train Epoch: 1 [16640/50000 (33%)]\tLoss: 2.001658\n",
      "Train Epoch: 1 [17280/50000 (35%)]\tLoss: 1.991203\n",
      "Train Epoch: 1 [17920/50000 (36%)]\tLoss: 1.945821\n",
      "Train Epoch: 1 [18560/50000 (37%)]\tLoss: 1.914389\n",
      "Train Epoch: 1 [19200/50000 (38%)]\tLoss: 2.004545\n",
      "Train Epoch: 1 [19840/50000 (40%)]\tLoss: 1.955609\n",
      "Train Epoch: 1 [20480/50000 (41%)]\tLoss: 1.920524\n",
      "Train Epoch: 1 [21120/50000 (42%)]\tLoss: 2.021856\n",
      "Train Epoch: 1 [21760/50000 (43%)]\tLoss: 1.904659\n",
      "Train Epoch: 1 [22400/50000 (45%)]\tLoss: 1.896703\n",
      "Train Epoch: 1 [23040/50000 (46%)]\tLoss: 1.951645\n",
      "Train Epoch: 1 [23680/50000 (47%)]\tLoss: 1.932071\n",
      "Train Epoch: 1 [24320/50000 (49%)]\tLoss: 1.910734\n",
      "Train Epoch: 1 [24960/50000 (50%)]\tLoss: 1.889464\n",
      "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 1.956754\n",
      "Train Epoch: 1 [26240/50000 (52%)]\tLoss: 1.948167\n",
      "Train Epoch: 1 [26880/50000 (54%)]\tLoss: 1.925936\n",
      "Train Epoch: 1 [27520/50000 (55%)]\tLoss: 1.986050\n",
      "Train Epoch: 1 [28160/50000 (56%)]\tLoss: 1.880604\n",
      "Train Epoch: 1 [28800/50000 (58%)]\tLoss: 1.941579\n",
      "Train Epoch: 1 [29440/50000 (59%)]\tLoss: 2.015073\n",
      "Train Epoch: 1 [30080/50000 (60%)]\tLoss: 1.868817\n",
      "Train Epoch: 1 [30720/50000 (61%)]\tLoss: 1.941473\n",
      "Train Epoch: 1 [31360/50000 (63%)]\tLoss: 1.971477\n",
      "Train Epoch: 1 [32000/50000 (64%)]\tLoss: 1.946969\n",
      "Train Epoch: 1 [32640/50000 (65%)]\tLoss: 1.923934\n",
      "Train Epoch: 1 [33280/50000 (66%)]\tLoss: 1.901559\n",
      "Train Epoch: 1 [33920/50000 (68%)]\tLoss: 1.969626\n",
      "Train Epoch: 1 [34560/50000 (69%)]\tLoss: 1.916977\n",
      "Train Epoch: 1 [35200/50000 (70%)]\tLoss: 1.821301\n",
      "Train Epoch: 1 [35840/50000 (72%)]\tLoss: 1.993145\n",
      "Train Epoch: 1 [36480/50000 (73%)]\tLoss: 1.856003\n",
      "Train Epoch: 1 [37120/50000 (74%)]\tLoss: 1.896577\n",
      "Train Epoch: 1 [37760/50000 (75%)]\tLoss: 1.918470\n",
      "Train Epoch: 1 [38400/50000 (77%)]\tLoss: 1.878833\n",
      "Train Epoch: 1 [39040/50000 (78%)]\tLoss: 1.876477\n",
      "Train Epoch: 1 [39680/50000 (79%)]\tLoss: 1.819373\n",
      "Train Epoch: 1 [40320/50000 (81%)]\tLoss: 1.941147\n",
      "Train Epoch: 1 [40960/50000 (82%)]\tLoss: 1.896053\n",
      "Train Epoch: 1 [41600/50000 (83%)]\tLoss: 1.873442\n",
      "Train Epoch: 1 [42240/50000 (84%)]\tLoss: 1.790522\n",
      "Train Epoch: 1 [42880/50000 (86%)]\tLoss: 1.972152\n",
      "Train Epoch: 1 [43520/50000 (87%)]\tLoss: 1.869463\n",
      "Train Epoch: 1 [44160/50000 (88%)]\tLoss: 1.792208\n",
      "Train Epoch: 1 [44800/50000 (90%)]\tLoss: 1.902431\n",
      "Train Epoch: 1 [45440/50000 (91%)]\tLoss: 1.872761\n",
      "Train Epoch: 1 [46080/50000 (92%)]\tLoss: 1.900739\n",
      "Train Epoch: 1 [46720/50000 (93%)]\tLoss: 1.860709\n",
      "Train Epoch: 1 [47360/50000 (95%)]\tLoss: 1.894731\n",
      "Train Epoch: 1 [48000/50000 (96%)]\tLoss: 1.863853\n",
      "Train Epoch: 1 [48640/50000 (97%)]\tLoss: 1.866995\n",
      "Train Epoch: 1 [49280/50000 (98%)]\tLoss: 1.847976\n",
      "Train Epoch: 1 [49920/50000 (100%)]\tLoss: 1.980704\n",
      "\n",
      "Test set: Avg. loss: -0.5506, Accuracy: 5834/10000 (58%)\n",
      "\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLoss: 1.783700\n",
      "Train Epoch: 2 [640/50000 (1%)]\tLoss: 1.838482\n",
      "Train Epoch: 2 [1280/50000 (3%)]\tLoss: 1.934996\n",
      "Train Epoch: 2 [1920/50000 (4%)]\tLoss: 1.855713\n",
      "Train Epoch: 2 [2560/50000 (5%)]\tLoss: 1.854805\n",
      "Train Epoch: 2 [3200/50000 (6%)]\tLoss: 1.926975\n",
      "Train Epoch: 2 [3840/50000 (8%)]\tLoss: 1.960422\n",
      "Train Epoch: 2 [4480/50000 (9%)]\tLoss: 1.772005\n",
      "Train Epoch: 2 [5120/50000 (10%)]\tLoss: 1.831529\n",
      "Train Epoch: 2 [5760/50000 (12%)]\tLoss: 1.847130\n",
      "Train Epoch: 2 [6400/50000 (13%)]\tLoss: 1.886399\n",
      "Train Epoch: 2 [7040/50000 (14%)]\tLoss: 1.740132\n",
      "Train Epoch: 2 [7680/50000 (15%)]\tLoss: 1.870594\n",
      "Train Epoch: 2 [8320/50000 (17%)]\tLoss: 1.812325\n",
      "Train Epoch: 2 [8960/50000 (18%)]\tLoss: 1.889402\n",
      "Train Epoch: 2 [9600/50000 (19%)]\tLoss: 1.878495\n",
      "Train Epoch: 2 [10240/50000 (20%)]\tLoss: 1.764595\n",
      "Train Epoch: 2 [10880/50000 (22%)]\tLoss: 1.858950\n",
      "Train Epoch: 2 [11520/50000 (23%)]\tLoss: 1.855024\n",
      "Train Epoch: 2 [12160/50000 (24%)]\tLoss: 1.860341\n",
      "Train Epoch: 2 [12800/50000 (26%)]\tLoss: 1.784402\n",
      "Train Epoch: 2 [13440/50000 (27%)]\tLoss: 1.783674\n",
      "Train Epoch: 2 [14080/50000 (28%)]\tLoss: 1.836283\n",
      "Train Epoch: 2 [14720/50000 (29%)]\tLoss: 1.885581\n",
      "Train Epoch: 2 [15360/50000 (31%)]\tLoss: 1.851524\n",
      "Train Epoch: 2 [16000/50000 (32%)]\tLoss: 1.755246\n",
      "Train Epoch: 2 [16640/50000 (33%)]\tLoss: 1.796982\n",
      "Train Epoch: 2 [17280/50000 (35%)]\tLoss: 1.819657\n",
      "Train Epoch: 2 [17920/50000 (36%)]\tLoss: 1.820880\n",
      "Train Epoch: 2 [18560/50000 (37%)]\tLoss: 1.783156\n",
      "Train Epoch: 2 [19200/50000 (38%)]\tLoss: 1.850936\n",
      "Train Epoch: 2 [19840/50000 (40%)]\tLoss: 1.835395\n",
      "Train Epoch: 2 [20480/50000 (41%)]\tLoss: 1.726565\n",
      "Train Epoch: 2 [21120/50000 (42%)]\tLoss: 1.797184\n",
      "Train Epoch: 2 [21760/50000 (43%)]\tLoss: 1.795795\n",
      "Train Epoch: 2 [22400/50000 (45%)]\tLoss: 1.844370\n",
      "Train Epoch: 2 [23040/50000 (46%)]\tLoss: 1.727101\n",
      "Train Epoch: 2 [23680/50000 (47%)]\tLoss: 1.865379\n",
      "Train Epoch: 2 [24320/50000 (49%)]\tLoss: 1.820799\n",
      "Train Epoch: 2 [24960/50000 (50%)]\tLoss: 1.890895\n",
      "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 1.829522\n",
      "Train Epoch: 2 [26240/50000 (52%)]\tLoss: 1.848046\n",
      "Train Epoch: 2 [26880/50000 (54%)]\tLoss: 1.909580\n",
      "Train Epoch: 2 [27520/50000 (55%)]\tLoss: 1.812910\n",
      "Train Epoch: 2 [28160/50000 (56%)]\tLoss: 1.813468\n",
      "Train Epoch: 2 [28800/50000 (58%)]\tLoss: 1.835760\n",
      "Train Epoch: 2 [29440/50000 (59%)]\tLoss: 1.765878\n",
      "Train Epoch: 2 [30080/50000 (60%)]\tLoss: 1.832286\n",
      "Train Epoch: 2 [30720/50000 (61%)]\tLoss: 1.887747\n",
      "Train Epoch: 2 [31360/50000 (63%)]\tLoss: 1.885858\n",
      "Train Epoch: 2 [32000/50000 (64%)]\tLoss: 1.810906\n",
      "Train Epoch: 2 [32640/50000 (65%)]\tLoss: 1.834507\n",
      "Train Epoch: 2 [33280/50000 (66%)]\tLoss: 1.798635\n",
      "Train Epoch: 2 [33920/50000 (68%)]\tLoss: 1.792107\n",
      "Train Epoch: 2 [34560/50000 (69%)]\tLoss: 1.819787\n",
      "Train Epoch: 2 [35200/50000 (70%)]\tLoss: 1.782147\n",
      "Train Epoch: 2 [35840/50000 (72%)]\tLoss: 1.812473\n",
      "Train Epoch: 2 [36480/50000 (73%)]\tLoss: 1.801030\n",
      "Train Epoch: 2 [37120/50000 (74%)]\tLoss: 1.807194\n",
      "Train Epoch: 2 [37760/50000 (75%)]\tLoss: 1.774539\n",
      "Train Epoch: 2 [38400/50000 (77%)]\tLoss: 1.760439\n",
      "Train Epoch: 2 [39040/50000 (78%)]\tLoss: 1.778690\n",
      "Train Epoch: 2 [39680/50000 (79%)]\tLoss: 1.752387\n",
      "Train Epoch: 2 [40320/50000 (81%)]\tLoss: 1.854741\n",
      "Train Epoch: 2 [40960/50000 (82%)]\tLoss: 1.757617\n",
      "Train Epoch: 2 [41600/50000 (83%)]\tLoss: 1.828776\n",
      "Train Epoch: 2 [42240/50000 (84%)]\tLoss: 1.887993\n",
      "Train Epoch: 2 [42880/50000 (86%)]\tLoss: 1.799758\n",
      "Train Epoch: 2 [43520/50000 (87%)]\tLoss: 1.775041\n",
      "Train Epoch: 2 [44160/50000 (88%)]\tLoss: 1.824099\n",
      "Train Epoch: 2 [44800/50000 (90%)]\tLoss: 1.743039\n",
      "Train Epoch: 2 [45440/50000 (91%)]\tLoss: 1.838898\n",
      "Train Epoch: 2 [46080/50000 (92%)]\tLoss: 1.803080\n",
      "Train Epoch: 2 [46720/50000 (93%)]\tLoss: 1.774594\n",
      "Train Epoch: 2 [47360/50000 (95%)]\tLoss: 1.768912\n",
      "Train Epoch: 2 [48000/50000 (96%)]\tLoss: 1.850053\n",
      "Train Epoch: 2 [48640/50000 (97%)]\tLoss: 1.844882\n",
      "Train Epoch: 2 [49280/50000 (98%)]\tLoss: 1.928761\n",
      "Train Epoch: 2 [49920/50000 (100%)]\tLoss: 1.729047\n",
      "\n",
      "Test set: Avg. loss: -0.6386, Accuracy: 6618/10000 (66%)\n",
      "\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLoss: 1.715591\n",
      "Train Epoch: 3 [640/50000 (1%)]\tLoss: 1.782579\n",
      "Train Epoch: 3 [1280/50000 (3%)]\tLoss: 1.730861\n",
      "Train Epoch: 3 [1920/50000 (4%)]\tLoss: 1.827203\n",
      "Train Epoch: 3 [2560/50000 (5%)]\tLoss: 1.822228\n",
      "Train Epoch: 3 [3200/50000 (6%)]\tLoss: 1.764319\n",
      "Train Epoch: 3 [3840/50000 (8%)]\tLoss: 1.786513\n",
      "Train Epoch: 3 [4480/50000 (9%)]\tLoss: 1.769401\n",
      "Train Epoch: 3 [5120/50000 (10%)]\tLoss: 1.778682\n",
      "Train Epoch: 3 [5760/50000 (12%)]\tLoss: 1.808018\n",
      "Train Epoch: 3 [6400/50000 (13%)]\tLoss: 1.757385\n",
      "Train Epoch: 3 [7040/50000 (14%)]\tLoss: 1.721967\n",
      "Train Epoch: 3 [7680/50000 (15%)]\tLoss: 1.670611\n",
      "Train Epoch: 3 [8320/50000 (17%)]\tLoss: 1.719524\n",
      "Train Epoch: 3 [8960/50000 (18%)]\tLoss: 1.743854\n",
      "Train Epoch: 3 [9600/50000 (19%)]\tLoss: 1.724362\n",
      "Train Epoch: 3 [10240/50000 (20%)]\tLoss: 1.754925\n",
      "Train Epoch: 3 [10880/50000 (22%)]\tLoss: 1.771657\n",
      "Train Epoch: 3 [11520/50000 (23%)]\tLoss: 1.787727\n",
      "Train Epoch: 3 [12160/50000 (24%)]\tLoss: 1.740208\n",
      "Train Epoch: 3 [12800/50000 (26%)]\tLoss: 1.744650\n",
      "Train Epoch: 3 [13440/50000 (27%)]\tLoss: 1.669513\n",
      "Train Epoch: 3 [14080/50000 (28%)]\tLoss: 1.807179\n",
      "Train Epoch: 3 [14720/50000 (29%)]\tLoss: 1.775436\n",
      "Train Epoch: 3 [15360/50000 (31%)]\tLoss: 1.797116\n",
      "Train Epoch: 3 [16000/50000 (32%)]\tLoss: 1.752531\n",
      "Train Epoch: 3 [16640/50000 (33%)]\tLoss: 1.741727\n",
      "Train Epoch: 3 [17280/50000 (35%)]\tLoss: 1.767372\n",
      "Train Epoch: 3 [17920/50000 (36%)]\tLoss: 1.701864\n",
      "Train Epoch: 3 [18560/50000 (37%)]\tLoss: 1.772920\n",
      "Train Epoch: 3 [19200/50000 (38%)]\tLoss: 1.757501\n",
      "Train Epoch: 3 [19840/50000 (40%)]\tLoss: 1.815641\n",
      "Train Epoch: 3 [20480/50000 (41%)]\tLoss: 1.695260\n",
      "Train Epoch: 3 [21120/50000 (42%)]\tLoss: 1.706267\n",
      "Train Epoch: 3 [21760/50000 (43%)]\tLoss: 1.785109\n",
      "Train Epoch: 3 [22400/50000 (45%)]\tLoss: 1.760387\n",
      "Train Epoch: 3 [23040/50000 (46%)]\tLoss: 1.791550\n",
      "Train Epoch: 3 [23680/50000 (47%)]\tLoss: 1.807545\n",
      "Train Epoch: 3 [24320/50000 (49%)]\tLoss: 1.696688\n",
      "Train Epoch: 3 [24960/50000 (50%)]\tLoss: 1.798334\n",
      "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 1.796973\n",
      "Train Epoch: 3 [26240/50000 (52%)]\tLoss: 1.693492\n",
      "Train Epoch: 3 [26880/50000 (54%)]\tLoss: 1.746955\n",
      "Train Epoch: 3 [27520/50000 (55%)]\tLoss: 1.755044\n",
      "Train Epoch: 3 [28160/50000 (56%)]\tLoss: 1.800052\n",
      "Train Epoch: 3 [28800/50000 (58%)]\tLoss: 1.735664\n",
      "Train Epoch: 3 [29440/50000 (59%)]\tLoss: 1.720819\n",
      "Train Epoch: 3 [30080/50000 (60%)]\tLoss: 1.787797\n",
      "Train Epoch: 3 [30720/50000 (61%)]\tLoss: 1.685198\n",
      "Train Epoch: 3 [31360/50000 (63%)]\tLoss: 1.729182\n",
      "Train Epoch: 3 [32000/50000 (64%)]\tLoss: 1.769365\n",
      "Train Epoch: 3 [32640/50000 (65%)]\tLoss: 1.803460\n",
      "Train Epoch: 3 [33280/50000 (66%)]\tLoss: 1.747233\n",
      "Train Epoch: 3 [33920/50000 (68%)]\tLoss: 1.753979\n",
      "Train Epoch: 3 [34560/50000 (69%)]\tLoss: 1.770642\n",
      "Train Epoch: 3 [35200/50000 (70%)]\tLoss: 1.657061\n",
      "Train Epoch: 3 [35840/50000 (72%)]\tLoss: 1.699231\n",
      "Train Epoch: 3 [36480/50000 (73%)]\tLoss: 1.750609\n",
      "Train Epoch: 3 [37120/50000 (74%)]\tLoss: 1.755601\n",
      "Train Epoch: 3 [37760/50000 (75%)]\tLoss: 1.782271\n",
      "Train Epoch: 3 [38400/50000 (77%)]\tLoss: 1.720051\n",
      "Train Epoch: 3 [39040/50000 (78%)]\tLoss: 1.769354\n",
      "Train Epoch: 3 [39680/50000 (79%)]\tLoss: 1.682441\n",
      "Train Epoch: 3 [40320/50000 (81%)]\tLoss: 1.736185\n",
      "Train Epoch: 3 [40960/50000 (82%)]\tLoss: 1.714392\n",
      "Train Epoch: 3 [41600/50000 (83%)]\tLoss: 1.766998\n",
      "Train Epoch: 3 [42240/50000 (84%)]\tLoss: 1.702011\n",
      "Train Epoch: 3 [42880/50000 (86%)]\tLoss: 1.721434\n",
      "Train Epoch: 3 [43520/50000 (87%)]\tLoss: 1.710654\n",
      "Train Epoch: 3 [44160/50000 (88%)]\tLoss: 1.754848\n",
      "Train Epoch: 3 [44800/50000 (90%)]\tLoss: 1.807200\n",
      "Train Epoch: 3 [45440/50000 (91%)]\tLoss: 1.727297\n",
      "Train Epoch: 3 [46080/50000 (92%)]\tLoss: 1.757778\n",
      "Train Epoch: 3 [46720/50000 (93%)]\tLoss: 1.848887\n",
      "Train Epoch: 3 [47360/50000 (95%)]\tLoss: 1.764772\n",
      "Train Epoch: 3 [48000/50000 (96%)]\tLoss: 1.712744\n",
      "Train Epoch: 3 [48640/50000 (97%)]\tLoss: 1.661993\n",
      "Train Epoch: 3 [49280/50000 (98%)]\tLoss: 1.710638\n",
      "Train Epoch: 3 [49920/50000 (100%)]\tLoss: 1.741409\n",
      "\n",
      "Test set: Avg. loss: -0.6947, Accuracy: 7143/10000 (71%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test()\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
