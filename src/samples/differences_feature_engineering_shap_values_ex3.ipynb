{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b48f800-d2d2-4bd7-9bd7-f6f9cfd6740c",
   "metadata": {},
   "source": [
    "# Feature Engineering with SHAP values Experiment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a73a1f-e932-47bb-9605-f5b5c5754612",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b4bc41-26c2-4fca-a614-ef28cea9d45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.flush_and_unmount()\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "import sys\n",
    "sys.path.append('/content/drive/My Drive/Colab Notebooks')\n",
    "sys.path.append('/content/drive/My Drive/Colab Notebooks/federated_learning')\n",
    "\n",
    "!pip install shap==0.40.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a70021e8-dc00-42e7-8bb7-ee4301741e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41448db-17cb-4a42-bacd-fd157ce28ac7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Experimental Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b4898aa8-0d37-4f50-b0be-e43e398612aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from federated_learning.utils import SHAPUtil, experiment_util, Visualizer\n",
    "from federated_learning import ClientPlane, Configuration, ObserverConfiguration\n",
    "from federated_learning.server import Server\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "792ca166-f3d7-4e15-92cc-6d54c7989729",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_similarity_values(s_client, s_server):\n",
    "    import numpy as np\n",
    "    cos_similarity = [[] for i in range(10)]\n",
    "    shap_subtract = np.subtract(s_client, s_server)\n",
    "    for row_idx, row in enumerate(shap_subtract):\n",
    "        for img_idx, image in enumerate(row):\n",
    "                cos_similarity[row_idx].append(round(np.sum(image.flatten()), 3))\n",
    "\n",
    "    print(np.matrix(cos_similarity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "49b4532f-b186-47a9-867a-ec27ddbabe8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "476b47a5-87c0-49b7-8b20-cbe286c75662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.8.0'"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "d7a592b2-117f-41c4-9de1-a4150c48035f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.21.6'"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "11b5b463-a3f6-4100-a908-f167b84455fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_similarity_values(s_client, s_server):\n",
    "    import numpy as np\n",
    "    cos_similarity_server = [[] for i in range(10)]\n",
    "    cos_similarity_client = [[] for i in range(10)]\n",
    "    shap_subtract = np.subtract(s_client, s_server)\n",
    "    for row_idx, row in enumerate(s_server):\n",
    "        for img_idx, image in enumerate(row):\n",
    "                cos_similarity_server[row_idx].append(np.sum(image.flatten()))\n",
    "    for row_idx, row in enumerate(s_client):\n",
    "        for img_idx, image in enumerate(row):\n",
    "                cos_similarity_client[row_idx].append(np.sum(image.flatten()))\n",
    "    spatial.distance.cosine(np.array(cos_similarity_server).flatten(), np.array(cos_similarity_client).flatten())\n",
    "    print(spatial.distance.cosine(np.array(cos_similarity_server).flatten(), np.array(cos_similarity_client).flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "844e8c3d-9ac7-49c4-b06c-ae145be6b4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_similarity_values(s_client, s_server):\n",
    "    import numpy as np\n",
    "    cos_similarity = [[] for i in range(10)]\n",
    "    shap_subtract = np.subtract(s_client, s_server)\n",
    "    for row_idx, row in enumerate(s_client):\n",
    "        for img_idx, image in enumerate(row):\n",
    "                cos_similarity[row_idx].append(spatial.distance.cosine(image.flatten(),s_server[row_idx][img_idx].flatten()))\n",
    "    \n",
    "    print(cos_similarity[5])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6078464c-3ec0-4085-9b9c-5a6517b5f83d",
   "metadata": {},
   "source": [
    "## MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3d70d54c-5b1f-4155-8c2f-bc504c4c5b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from federated_learning.nets import MNISTCNN\n",
    "from federated_learning.dataset import MNISTDataset\n",
    "import os\n",
    "config = Configuration()\n",
    "config.POISONED_CLIENTS = 0\n",
    "config.DATA_POISONING_PERCENTAGE = 1\n",
    "config.DATASET = MNISTDataset\n",
    "config.MODELNAME = config.MNIST_NAME\n",
    "config.NETWORK = MNISTCNN\n",
    "observer_config = ObserverConfiguration()\n",
    "observer_config.experiment_type = \"shap_fl_poisoned\"\n",
    "observer_config.experiment_id = 1\n",
    "observer_config.test = False\n",
    "observer_config.datasetObserverConfiguration = \"MNIST\"\n",
    "neutral_label = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7523594-78d7-4902-a244-98e371ed993c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Colab Settigns\n",
    "config.TEMP = os.path.join('/content/drive/My Drive/Colab Notebooks/temp')\n",
    "config.FMNIST_DATASET_PATH = os.path.join('/content/data/fmnist')\n",
    "config.MNIST_DATASET_PATH = os.path.join('/content/data/mnist')\n",
    "config.CIFAR10_DATASET_PATH = os.path.join('/content/data/cifar10')\n",
    "config.VM_URL = \"none\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b972cb31-adf5-4c27-808b-e151cecc3f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST training data loaded.\n",
      "MNIST test data loaded.\n",
      "Create 200 clients with dataset of size 300\n"
     ]
    }
   ],
   "source": [
    "data = config.DATASET(config)\n",
    "shap_util = SHAPUtil(data.test_dataloader) \n",
    "server = Server(config, observer_config,data.train_dataloader, data.test_dataloader, shap_util)\n",
    "visualizer = Visualizer(shap_util)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078b7a1b-9860-4cf6-a5bc-1b4ee4b80cf9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Experiment Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a070b8f-c3ee-43a8-8cf9-d6e1a791d57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import torch\n",
    "import os\n",
    "for i in range(200):\n",
    "    if (i+1) in [2, 5,10,75,100,200]:\n",
    "        file = \"./temp/models/ex6/MNIST_round_{}.model\".format(i+1)\n",
    "        if not os.path.exists(os.path.dirname(file)):\n",
    "                os.makedirs(os.path.dirname(file))\n",
    "        torch.save(server.net.state_dict(), file)\n",
    "    experiment_util.set_rounds(client_plane, server, i+1)\n",
    "    experiment_util.run_round(client_plane, server, i+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53511113-cd4d-4f1e-afa1-238e6905f4d6",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "3d857037-940c-4081-bc0f-bb14a64df276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST training data loaded.\n",
      "MNIST test data loaded.\n",
      "Create 200 clients with dataset of size 300\n",
      "Load default model successfully\n",
      "20/200 clients cleaned\n",
      "40/200 clients cleaned\n",
      "60/200 clients cleaned\n",
      "80/200 clients cleaned\n",
      "100/200 clients cleaned\n",
      "120/200 clients cleaned\n",
      "140/200 clients cleaned\n",
      "160/200 clients cleaned\n",
      "180/200 clients cleaned\n",
      "200/200 clients cleaned\n",
      "Cleaning successfully\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9645/10000 (96%)\n",
      "\n",
      "Original tensor([0.9929, 0.9833, 0.9554, 0.9436, 0.9674, 0.9664, 0.9760, 0.9582, 0.9415,\n",
      "        0.9594]) tensor([0.9567, 0.9876, 0.9527, 0.9744, 0.9754, 0.9610, 0.9709, 0.9535, 0.9704,\n",
      "        0.9416]) 0.9645\n",
      "Poison 100/200 clients\n",
      "Flip 100.0% of the 1 labels to 7\n",
      "[ 57  16  66 123 116 151  51 152  96 141 158 134 139 142 154 164 100 128\n",
      "  90   9  77  50  25  58 149 132  14  23   1 190  60 161 172 136  15  10\n",
      "   2  80 198 137  47 150 129  88   0 175 178  95  35   8  48  17 163 124\n",
      " 199  92  33 131 181 113 156  11  54 140 191  22 105 115 171 111 114 120\n",
      "  82 119  75  13 180 103  56 170 195  70 157  86 197  31 155  89 173 188\n",
      " 112  38 108  18  91 101  85  84  64  37]\n",
      "20/100 clients poisoned\n",
      "40/100 clients poisoned\n",
      "60/100 clients poisoned\n",
      "80/100 clients poisoned\n",
      "100/100 clients poisoned\n",
      "Clean\n",
      "0.003465114686834969\n",
      "0.0035435619291807052\n",
      "Poisoned\n",
      "0.03803526171519245\n",
      "0.03949306657460272\n",
      "Load default model successfully\n",
      "20/200 clients cleaned\n",
      "40/200 clients cleaned\n",
      "60/200 clients cleaned\n",
      "80/200 clients cleaned\n",
      "100/200 clients cleaned\n",
      "120/200 clients cleaned\n",
      "140/200 clients cleaned\n",
      "160/200 clients cleaned\n",
      "180/200 clients cleaned\n",
      "200/200 clients cleaned\n",
      "Cleaning successfully\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "config.FROM_LABEL = 1\n",
    "config.TO_LABEL = 7\n",
    "shap_images = [config.FROM_LABEL ,config.TO_LABEL]\n",
    "for j in [100]:\n",
    "    data = config.DATASET(config)\n",
    "    client_plane = ClientPlane(config, observer_config, data, shap_util)\n",
    "    model_file = file = \"./temp/models/ex5/MNIST_round_{}.model\".format(j)\n",
    "    server.net =  MNISTCNN()\n",
    "    server.net.load_state_dict(torch.load(model_file))\n",
    "    client_plane.reset_default_client_nets()\n",
    "    client_plane.reset_poisoning_attack()\n",
    "\n",
    "    server.test()\n",
    "    recall, precision, accuracy = server.analize_test()\n",
    "    print(\"Original\", recall, precision, accuracy)\n",
    "    server_shap = server.get_shap_values()\n",
    "\n",
    "    config.POISONED_CLIENTS = 100\n",
    "    experiment_util.update_configs(client_plane, server, config, observer_config)\n",
    "    client_plane.poison_clients()\n",
    "    clean_clients = experiment_util.select_random_clean(client_plane, config, 100)\n",
    "    poisoned_clients = experiment_util.select_poisoned(client_plane, 100)\n",
    "\n",
    "    print(\"Clean\")\n",
    "    for i in clean_clients[:2]:\n",
    "        client_plane.update_clients(server.get_nn_parameters())\n",
    "        client_plane.clients[i].train(j+1)\n",
    "        clean_client_shap = client_plane.clients[i].get_shap_values()\n",
    "        cos_similarity_values(clean_client_shap, server_shap)\n",
    "\n",
    "    print(\"Poisoned\")\n",
    "    server.net =  MNISTCNN()\n",
    "    server.net.load_state_dict(torch.load(model_file))\n",
    "    for i in poisoned_clients[:2]:\n",
    "        client_plane.update_clients(server.get_nn_parameters())    \n",
    "        client_plane.clients[i].train(j+1)\n",
    "        poisoned_client_shap = client_plane.clients[i].get_shap_values()\n",
    "        cos_similarity_values(poisoned_client_shap, server_shap)\n",
    "    client_plane.reset_default_client_nets()\n",
    "    client_plane.reset_poisoning_attack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "4da957c2-02d2-4a82-a9e1-6bc77dd37152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST training data loaded.\n",
      "MNIST test data loaded.\n",
      "Create 200 clients with dataset of size 300\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9645/10000 (96%)\n",
      "\n",
      "Original tensor([0.9929, 0.9833, 0.9554, 0.9436, 0.9674, 0.9664, 0.9760, 0.9582, 0.9415,\n",
      "        0.9594]) tensor([0.9567, 0.9876, 0.9527, 0.9744, 0.9754, 0.9610, 0.9709, 0.9535, 0.9704,\n",
      "        0.9416]) 0.9645\n",
      "5421\n",
      "Poison 100/200 clients\n",
      "Flip 100.0% of the 5 labels to 4\n",
      "[ 52 157  23  40 196 193 176 182 173  14 129   0  37   5  75 131  70  81\n",
      " 108  97 133 170  30 148 194  26  35 112  34 141   4  98 127   9 147  61\n",
      "  60   7  99  93  73 135  48 132 152  20 130  54 109  87 168 155 179 106\n",
      "  85  33 134 180  41 198  88 162  64 169 184   2  90 151  12 172 143 120\n",
      " 105 123  58  82   8 185   6  67 122  55  18  38  22  17 104 125  29 114\n",
      " 100  94  69 186  25 117 118  84 178  68]\n",
      "20/100 clients poisoned\n",
      "40/100 clients poisoned\n",
      "60/100 clients poisoned\n",
      "80/100 clients poisoned\n",
      "100/100 clients poisoned\n",
      "Clean\n",
      "0.001898895787324828\n",
      "0.001324380081854648\n",
      "2733\n",
      "Poisoned\n",
      "0.09177327677261538\n",
      "0.04951307714066844\n",
      "Load default model successfully\n",
      "20/200 clients cleaned\n",
      "40/200 clients cleaned\n",
      "60/200 clients cleaned\n",
      "80/200 clients cleaned\n",
      "100/200 clients cleaned\n",
      "120/200 clients cleaned\n",
      "140/200 clients cleaned\n",
      "160/200 clients cleaned\n",
      "180/200 clients cleaned\n",
      "200/200 clients cleaned\n",
      "Cleaning successfully\n",
      "tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5])\n",
      "5421\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "config.FROM_LABEL = 5\n",
    "config.TO_LABEL = 4\n",
    "shap_images = [config.FROM_LABEL ,config.TO_LABEL]\n",
    "\n",
    "for j in [100]:\n",
    "    data = config.DATASET(config)\n",
    "    client_plane = ClientPlane(config, observer_config, data, shap_util)\n",
    "    model_file = file = \"./temp/models/ex5/MNIST_round_{}.model\".format(j)\n",
    "    server.net =  MNISTCNN()\n",
    "    server.net.load_state_dict(torch.load(model_file))\n",
    "    server.test()\n",
    "    recall, precision, accuracy = server.analize_test()\n",
    "    print(\"Original\", recall, precision, accuracy)\n",
    "    server_shap = server.get_shap_values()\n",
    "    print(len(client_plane.clients[poisoned_clients[0]].train_dataloader.dataset.dataset.targets[client_plane.clients[poisoned_clients[0]].train_dataloader.dataset.dataset.targets == 5]))\n",
    "    \n",
    "    config.POISONED_CLIENTS = 100\n",
    "    experiment_util.update_configs(client_plane, server, config, observer_config)\n",
    "    client_plane.poison_clients()\n",
    "    clean_clients = experiment_util.select_random_clean(client_plane, config, 100)\n",
    "    poisoned_clients = experiment_util.select_poisoned(client_plane, 100)\n",
    "\n",
    "    print(\"Clean\")\n",
    "    for i in clean_clients[:2]:\n",
    "        client_plane.update_clients(server.get_nn_parameters())\n",
    "        client_plane.clients[i].train(j+1)\n",
    "        clean_client_shap = client_plane.clients[i].get_shap_values()\n",
    "        cos_similarity_values(clean_client_shap, server_shap)\n",
    "    print(len(client_plane.clients[poisoned_clients[0]].train_dataloader.dataset.dataset.targets[client_plane.clients[poisoned_clients[0]].train_dataloader.dataset.dataset.targets == 5]))\n",
    "\n",
    "    print(\"Poisoned\")\n",
    "    server.net =  MNISTCNN()\n",
    "    server.net.load_state_dict(torch.load(model_file))\n",
    "    for i in poisoned_clients[:2]:\n",
    "        client_plane.update_clients(server.get_nn_parameters())    \n",
    "        client_plane.clients[i].train(j+1)\n",
    "        poisoned_client_shap = client_plane.clients[i].get_shap_values()\n",
    "        cos_similarity_values(poisoned_client_shap, server_shap)\n",
    "    client_plane.reset_default_client_nets()\n",
    "    client_plane.reset_poisoning_attack()\n",
    "    print(client_plane.clients[poisoned_clients[0]].train_dataloader.dataset.dataset.targets[client_plane.clients[poisoned_clients[0]].poisoning_indices])\n",
    "    print(len(client_plane.clients[poisoned_clients[0]].train_dataloader.dataset.dataset.targets[client_plane.clients[poisoned_clients[0]].train_dataloader.dataset.dataset.targets == 5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "67c9ba68-588c-49d6-bc6c-8a4f99b03e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST training data loaded.\n",
      "MNIST test data loaded.\n",
      "Create 200 clients with dataset of size 300\n",
      "Load default model successfully\n",
      "20/200 clients cleaned\n",
      "40/200 clients cleaned\n",
      "60/200 clients cleaned\n",
      "80/200 clients cleaned\n",
      "100/200 clients cleaned\n",
      "120/200 clients cleaned\n",
      "140/200 clients cleaned\n",
      "160/200 clients cleaned\n",
      "180/200 clients cleaned\n",
      "200/200 clients cleaned\n",
      "Cleaning successfully\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9645/10000 (96%)\n",
      "\n",
      "Original tensor([0.9929, 0.9833, 0.9554, 0.9436, 0.9674, 0.9664, 0.9760, 0.9582, 0.9415,\n",
      "        0.9594]) tensor([0.9567, 0.9876, 0.9527, 0.9744, 0.9754, 0.9610, 0.9709, 0.9535, 0.9704,\n",
      "        0.9416]) 0.9645\n",
      "Poison 100/200 clients\n",
      "Flip 100.0% of the 3 labels to 8\n",
      "[ 51 188 148 165  56 115 155  24 113  18 131 126  42  69  80 125  92  15\n",
      "  41  61 141  62  10 160  74 158 175  50  25  35  63 117 174 184  32   3\n",
      "  19  75 159 163   0 116 161 146 176   2 118 147  97 194  84 130  86 151\n",
      "  46 196  48 177 106  16  76  43 180 112 150 143  11 191  95 140 105  14\n",
      " 197 114 154 142  70 121  90 109 152 185  44  89  28 127 164  83 136  29\n",
      " 137  38 198 186 101 120  52 178 129   9]\n",
      "20/100 clients poisoned\n",
      "40/100 clients poisoned\n",
      "60/100 clients poisoned\n",
      "80/100 clients poisoned\n",
      "100/100 clients poisoned\n",
      "Clean\n",
      "0.005524717429030046\n",
      "0.005715401139850584\n",
      "Poisoned\n",
      "0.09338475193337581\n",
      "0.08831197650778044\n",
      "Load default model successfully\n",
      "20/200 clients cleaned\n",
      "40/200 clients cleaned\n",
      "60/200 clients cleaned\n",
      "80/200 clients cleaned\n",
      "100/200 clients cleaned\n",
      "120/200 clients cleaned\n",
      "140/200 clients cleaned\n",
      "160/200 clients cleaned\n",
      "180/200 clients cleaned\n",
      "200/200 clients cleaned\n",
      "Cleaning successfully\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "config.FROM_LABEL = 3\n",
    "config.TO_LABEL = 8\n",
    "shap_images = [config.FROM_LABEL ,config.TO_LABEL]\n",
    "for j in [100]:\n",
    "    data = config.DATASET(config)\n",
    "    client_plane = ClientPlane(config, observer_config, data, shap_util)\n",
    "    model_file = file = \"./temp/models/ex5/MNIST_round_{}.model\".format(j)\n",
    "    server.net =  MNISTCNN()\n",
    "    server.net.load_state_dict(torch.load(model_file))\n",
    "    client_plane.reset_default_client_nets()\n",
    "    client_plane.reset_poisoning_attack()\n",
    "\n",
    "    server.test()\n",
    "    recall, precision, accuracy = server.analize_test()\n",
    "    print(\"Original\", recall, precision, accuracy)\n",
    "    server_shap = server.get_shap_values()\n",
    "\n",
    "    config.POISONED_CLIENTS = 100\n",
    "    experiment_util.update_configs(client_plane, server, config, observer_config)\n",
    "    client_plane.poison_clients()\n",
    "    clean_clients = experiment_util.select_random_clean(client_plane, config, 100)\n",
    "    poisoned_clients = experiment_util.select_poisoned(client_plane, 100)\n",
    "\n",
    "    print(\"Clean\")\n",
    "    for i in clean_clients[:2]:\n",
    "        client_plane.update_clients(server.get_nn_parameters())\n",
    "        client_plane.clients[i].train(j+1)\n",
    "        clean_client_shap = client_plane.clients[i].get_shap_values()\n",
    "        cos_similarity_values(clean_client_shap, server_shap)\n",
    "\n",
    "    print(\"Poisoned\")\n",
    "    server.net =  MNISTCNN()\n",
    "    server.net.load_state_dict(torch.load(model_file))\n",
    "    for i in poisoned_clients[:2]:\n",
    "        client_plane.update_clients(server.get_nn_parameters())    \n",
    "        client_plane.clients[i].train(j+1)\n",
    "        poisoned_client_shap = client_plane.clients[i].get_shap_values()\n",
    "        cos_similarity_values(poisoned_client_shap, server_shap)\n",
    "    client_plane.reset_default_client_nets()\n",
    "    client_plane.reset_poisoning_attack()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
