{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b12f31ea-c88e-4255-a6e3-ff8ea7c255e4",
   "metadata": {},
   "source": [
    "# Experiment 3: Poisoning Attacks in Federated Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0506f7ba-cafc-45dc-95df-ecf1e9de0bf1",
   "metadata": {},
   "source": [
    "* Poisoning of\n",
    "    * experiment_id = 0; label flipping 5 -> 4,  poisoned_clients[0,10, 25, 50, 75, 100, 125, 150, 200] rounds 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bded64ba-e5ec-444b-af5e-8e969fb11ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from federated_learning.utils import SHAPUtil\n",
    "from federated_learning import ClientPlane, Configuration\n",
    "from federated_learning.server import Server\n",
    "from datetime import datetime\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4146637-5eb6-4413-994a-6868b4aa167f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObserverConfiguration():\n",
    "    experiment_type = \"shap_fl_poisoned\"\n",
    "    experiment_id = 0\n",
    "    test = False\n",
    "    dataset_type = \"MNIST\"\n",
    "    \n",
    "    # Client Configurations \n",
    "    client_name = \"client\"\n",
    "    client_type = \"client\"\n",
    "    \n",
    "    # Server Configurations \n",
    "    server_name = \"server\"\n",
    "    server_type = \"server\"\n",
    "    server_id = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14b7759e-dfd2-49a4-a719-4ddd72f002d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_rounds(rounds):\n",
    "    client_plane.set_rounds(rounds)\n",
    "    server.set_rounds(rounds)\n",
    "    \n",
    "def update_configs():\n",
    "    client_plane.update_config(config, observer_config)\n",
    "    server.update_config(config, observer_config)\n",
    "    \n",
    "def run_round(rounds):\n",
    "    # Federated Learning Round \n",
    "    client_plane.update_clients(server.get_nn_parameters())\n",
    "    selected_clients = server.select_clients()\n",
    "    client_parameters = client_plane.train_selected_clients(selected_clients)\n",
    "    server.aggregate_model(client_parameters)\n",
    "\n",
    "def select_random_clean():\n",
    "    idx = 0\n",
    "    while idx in client_plane.poisoned_clients:\n",
    "        idx = random.randint(0,config.NUMBER_OF_CLIENTS)\n",
    "    return idx\n",
    "\n",
    "def train_poisoned_client_only(rounds): \n",
    "    client_plane.clients[client_plane.poisoned_clients[0]].train(rounds)\n",
    "    client_plane.clients[client_plane.poisoned_clients[0]].push_metrics()\n",
    "    if rounds == 5: \n",
    "        print(client_plane.clients[client_plane.poisoned_clients[0]].train_dataloader.dataset.dataset.targets[client_plane.clients[client_plane.poisoned_clients[0]].poisoned_indices][0])\n",
    "    \n",
    "def train_clean_client_only(idx, rounds): \n",
    "    client_plane.clients[idx].train(rounds)\n",
    "    client_plane.clients[idx].push_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebaf31cd-c3cd-41d2-a097-9231c94ee361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST training data loaded.\n",
      "MNIST test data loaded.\n"
     ]
    }
   ],
   "source": [
    "config = Configuration()\n",
    "config.FROM_LABEL = 5\n",
    "config.TO_LABEL = 4\n",
    "data = config.DATASET(config)\n",
    "shap_util = SHAPUtil(data.test_dataloader)\n",
    "observer_config = ObserverConfiguration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5331f1e-3526-499d-bf05-650a562582dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#server.create_default_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cb7e804-9996-4aae-94e7-03ccdca03a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default model saved to:./temp/models\n",
      "Create 200 clients with dataset of size 300\n"
     ]
    }
   ],
   "source": [
    "server = Server(config, observer_config,data.train_dataloader, data.test_dataloader, shap_util)\n",
    "server.create_default_model()\n",
    "client_plane = ClientPlane(config, observer_config, data, shap_util)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4521dba2-fe32-4230-988f-da6b8f85f515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load default model successfully\n",
      "20/200 clients cleaned\n",
      "40/200 clients cleaned\n",
      "60/200 clients cleaned\n",
      "80/200 clients cleaned\n",
      "100/200 clients cleaned\n",
      "120/200 clients cleaned\n",
      "140/200 clients cleaned\n",
      "160/200 clients cleaned\n",
      "180/200 clients cleaned\n",
      "200/200 clients cleaned\n",
      "Cleaning successfully\n",
      "No poisoning due to 0. poisoned clients\n",
      "Round 1 finished\n",
      "Round 2 finished\n",
      "Round 3 finished\n",
      "Round 4 finished\n",
      "Round 5 finished\n",
      "Round 6 finished\n",
      "Round 7 finished\n",
      "Round 8 finished\n",
      "Round 9 finished\n",
      "\n",
      "Test set: Average loss: 0.0011, Accuracy: 8277/10000 (83%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully pushed server data to victoria metrics\n",
      "Round 10 finished\n",
      "Round 11 finished\n",
      "Round 12 finished\n",
      "Round 13 finished\n",
      "Round 14 finished\n",
      "Round 15 finished\n",
      "Round 16 finished\n",
      "Round 17 finished\n",
      "Round 18 finished\n",
      "Round 19 finished\n",
      "\n",
      "Test set: Average loss: 0.0006, Accuracy: 9019/10000 (90%)\n",
      "\n",
      "Successfully pushed server data to victoria metrics\n",
      "Round 20 finished\n",
      "Round 21 finished\n",
      "Round 22 finished\n",
      "Round 23 finished\n",
      "Round 24 finished\n",
      "Round 25 finished\n",
      "Round 26 finished\n",
      "Round 27 finished\n",
      "Round 28 finished\n",
      "Round 29 finished\n",
      "\n",
      "Test set: Average loss: 0.0004, Accuracy: 9263/10000 (93%)\n",
      "\n",
      "Successfully pushed server data to victoria metrics\n",
      "Round 30 finished\n",
      "Round 31 finished\n",
      "Round 32 finished\n",
      "Round 33 finished\n",
      "Round 34 finished\n",
      "Round 35 finished\n",
      "Round 36 finished\n",
      "Round 37 finished\n",
      "Round 38 finished\n",
      "Round 39 finished\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 9413/10000 (94%)\n",
      "\n",
      "Successfully pushed server data to victoria metrics\n",
      "Round 40 finished\n",
      "Round 41 finished\n",
      "Round 42 finished\n",
      "Round 43 finished\n",
      "Round 44 finished\n",
      "Round 45 finished\n",
      "Round 46 finished\n",
      "Round 47 finished\n",
      "Round 48 finished\n",
      "Model aggregation in round 50 was successful\n",
      "Round 49 finished\n",
      "\n",
      "Test set: Average loss: 0.0002, Accuracy: 9464/10000 (95%)\n",
      "\n",
      "Successfully pushed server data to victoria metrics\n",
      "Round 50 finished\n",
      "Round 51 finished\n",
      "Round 52 finished\n",
      "Round 53 finished\n",
      "Round 54 finished\n",
      "Round 55 finished\n",
      "Round 56 finished\n",
      "Round 57 finished\n",
      "Round 58 finished\n",
      "Round 59 finished\n",
      "\n",
      "Test set: Average loss: 0.0002, Accuracy: 9517/10000 (95%)\n",
      "\n",
      "Successfully pushed server data to victoria metrics\n",
      "Round 60 finished\n",
      "Round 61 finished\n",
      "Round 62 finished\n",
      "Round 63 finished\n",
      "Round 64 finished\n",
      "Round 65 finished\n",
      "Round 66 finished\n",
      "Round 67 finished\n",
      "Round 68 finished\n",
      "Round 69 finished\n",
      "\n",
      "Test set: Average loss: 0.0002, Accuracy: 9541/10000 (95%)\n",
      "\n",
      "Successfully pushed server data to victoria metrics\n",
      "Round 70 finished\n",
      "Round 71 finished\n",
      "Round 72 finished\n",
      "Round 73 finished\n",
      "Round 74 finished\n",
      "Round 75 finished\n",
      "Round 76 finished\n",
      "Round 77 finished\n",
      "Round 78 finished\n",
      "Round 79 finished\n",
      "\n",
      "Test set: Average loss: 0.0002, Accuracy: 9570/10000 (96%)\n",
      "\n",
      "Successfully pushed server data to victoria metrics\n",
      "Round 80 finished\n",
      "Round 81 finished\n",
      "Round 82 finished\n",
      "Round 83 finished\n",
      "Round 84 finished\n",
      "Round 85 finished\n",
      "Round 86 finished\n",
      "Round 87 finished\n",
      "Round 88 finished\n",
      "Round 89 finished\n",
      "\n",
      "Test set: Average loss: 0.0002, Accuracy: 9636/10000 (96%)\n",
      "\n",
      "Successfully pushed server data to victoria metrics\n",
      "Round 90 finished\n",
      "Round 91 finished\n",
      "Round 92 finished\n",
      "Round 93 finished\n",
      "Round 94 finished\n",
      "Round 95 finished\n",
      "Round 96 finished\n",
      "Round 97 finished\n",
      "Round 98 finished\n",
      "Model aggregation in round 100 was successful\n",
      "Round 99 finished\n",
      "Train Epoch: 101 [0/300 (0%)]\tLoss: 0.191377\n",
      "Train Epoch: 101 [10/300 (3%)]\tLoss: 0.047664\n",
      "Train Epoch: 101 [20/300 (7%)]\tLoss: 0.385724\n",
      "Train Epoch: 101 [30/300 (10%)]\tLoss: 0.543218\n",
      "Train Epoch: 101 [40/300 (13%)]\tLoss: 0.040668\n",
      "Train Epoch: 101 [50/300 (17%)]\tLoss: 0.911788\n",
      "Train Epoch: 101 [60/300 (20%)]\tLoss: 0.002868\n",
      "Train Epoch: 101 [70/300 (23%)]\tLoss: 1.082952\n",
      "Train Epoch: 101 [80/300 (27%)]\tLoss: 0.442557\n",
      "Train Epoch: 101 [90/300 (30%)]\tLoss: 0.092277\n",
      "Train Epoch: 101 [100/300 (33%)]\tLoss: 0.262772\n",
      "Train Epoch: 101 [110/300 (37%)]\tLoss: 0.287945\n",
      "Train Epoch: 101 [120/300 (40%)]\tLoss: 0.521857\n",
      "Train Epoch: 101 [130/300 (43%)]\tLoss: 0.465815\n",
      "Train Epoch: 101 [140/300 (47%)]\tLoss: 0.395457\n",
      "Train Epoch: 101 [150/300 (50%)]\tLoss: 0.479118\n",
      "Train Epoch: 101 [160/300 (53%)]\tLoss: 0.282706\n",
      "Train Epoch: 101 [170/300 (57%)]\tLoss: 0.385978\n",
      "Train Epoch: 101 [180/300 (60%)]\tLoss: 0.239234\n",
      "Train Epoch: 101 [190/300 (63%)]\tLoss: 0.519135\n",
      "Train Epoch: 101 [200/300 (67%)]\tLoss: 0.209263\n",
      "Train Epoch: 101 [210/300 (70%)]\tLoss: 0.147578\n",
      "Train Epoch: 101 [220/300 (73%)]\tLoss: 0.240891\n",
      "Train Epoch: 101 [230/300 (77%)]\tLoss: 0.050074\n",
      "Train Epoch: 101 [240/300 (80%)]\tLoss: 0.055890\n",
      "Train Epoch: 101 [250/300 (83%)]\tLoss: 0.120262\n",
      "Train Epoch: 101 [260/300 (87%)]\tLoss: 0.383238\n",
      "Train Epoch: 101 [270/300 (90%)]\tLoss: 0.846031\n",
      "Train Epoch: 101 [280/300 (93%)]\tLoss: 0.132529\n",
      "Train Epoch: 101 [290/300 (97%)]\tLoss: 0.068465\n",
      "Train Epoch: 101 [0/300 (0%)]\tLoss: 0.017185\n",
      "Train Epoch: 101 [10/300 (3%)]\tLoss: 0.064102\n",
      "Train Epoch: 101 [20/300 (7%)]\tLoss: 0.086400\n",
      "Train Epoch: 101 [30/300 (10%)]\tLoss: 0.045353\n",
      "Train Epoch: 101 [40/300 (13%)]\tLoss: 0.149064\n",
      "Train Epoch: 101 [50/300 (17%)]\tLoss: 0.392725\n",
      "Train Epoch: 101 [60/300 (20%)]\tLoss: 0.297955\n",
      "Train Epoch: 101 [70/300 (23%)]\tLoss: 0.193770\n",
      "Train Epoch: 101 [80/300 (27%)]\tLoss: 0.487569\n",
      "Train Epoch: 101 [90/300 (30%)]\tLoss: 0.087491\n",
      "Train Epoch: 101 [100/300 (33%)]\tLoss: 0.200184\n",
      "Train Epoch: 101 [110/300 (37%)]\tLoss: 0.228177\n",
      "Train Epoch: 101 [120/300 (40%)]\tLoss: 0.153679\n",
      "Train Epoch: 101 [130/300 (43%)]\tLoss: 0.387436\n",
      "Train Epoch: 101 [140/300 (47%)]\tLoss: 0.237988\n",
      "Train Epoch: 101 [150/300 (50%)]\tLoss: 0.080839\n",
      "Train Epoch: 101 [160/300 (53%)]\tLoss: 0.172836\n",
      "Train Epoch: 101 [170/300 (57%)]\tLoss: 0.397678\n",
      "Train Epoch: 101 [180/300 (60%)]\tLoss: 0.183299\n",
      "Train Epoch: 101 [190/300 (63%)]\tLoss: 0.109637\n",
      "Train Epoch: 101 [200/300 (67%)]\tLoss: 0.216525\n",
      "Train Epoch: 101 [210/300 (70%)]\tLoss: 0.222838\n",
      "Train Epoch: 101 [220/300 (73%)]\tLoss: 0.291703\n",
      "Train Epoch: 101 [230/300 (77%)]\tLoss: 0.507586\n",
      "Train Epoch: 101 [240/300 (80%)]\tLoss: 0.408372\n",
      "Train Epoch: 101 [250/300 (83%)]\tLoss: 0.101861\n",
      "Train Epoch: 101 [260/300 (87%)]\tLoss: 0.539457\n",
      "Train Epoch: 101 [270/300 (90%)]\tLoss: 0.123485\n",
      "Train Epoch: 101 [280/300 (93%)]\tLoss: 0.218553\n",
      "Train Epoch: 101 [290/300 (97%)]\tLoss: 0.093603\n",
      "Train Epoch: 101 [0/300 (0%)]\tLoss: 0.173198\n",
      "Train Epoch: 101 [10/300 (3%)]\tLoss: 0.053228\n",
      "Train Epoch: 101 [20/300 (7%)]\tLoss: 0.069538\n",
      "Train Epoch: 101 [30/300 (10%)]\tLoss: 0.086162\n",
      "Train Epoch: 101 [40/300 (13%)]\tLoss: 0.321037\n",
      "Train Epoch: 101 [50/300 (17%)]\tLoss: 0.105714\n",
      "Train Epoch: 101 [60/300 (20%)]\tLoss: 0.102367\n",
      "Train Epoch: 101 [70/300 (23%)]\tLoss: 0.790141\n",
      "Train Epoch: 101 [80/300 (27%)]\tLoss: 0.064579\n",
      "Train Epoch: 101 [90/300 (30%)]\tLoss: 0.019931\n",
      "Train Epoch: 101 [100/300 (33%)]\tLoss: 0.165823\n",
      "Train Epoch: 101 [110/300 (37%)]\tLoss: 0.063738\n",
      "Train Epoch: 101 [120/300 (40%)]\tLoss: 0.134439\n",
      "Train Epoch: 101 [130/300 (43%)]\tLoss: 0.788549\n",
      "Train Epoch: 101 [140/300 (47%)]\tLoss: 0.104973\n",
      "Train Epoch: 101 [150/300 (50%)]\tLoss: 0.786721\n",
      "Train Epoch: 101 [160/300 (53%)]\tLoss: 0.053785\n",
      "Train Epoch: 101 [170/300 (57%)]\tLoss: 0.029689\n",
      "Train Epoch: 101 [180/300 (60%)]\tLoss: 0.691723\n",
      "Train Epoch: 101 [190/300 (63%)]\tLoss: 0.387305\n",
      "Train Epoch: 101 [200/300 (67%)]\tLoss: 0.184661\n",
      "Train Epoch: 101 [210/300 (70%)]\tLoss: 0.019390\n",
      "Train Epoch: 101 [220/300 (73%)]\tLoss: 0.569812\n",
      "Train Epoch: 101 [230/300 (77%)]\tLoss: 0.020591\n",
      "Train Epoch: 101 [240/300 (80%)]\tLoss: 0.088103\n",
      "Train Epoch: 101 [250/300 (83%)]\tLoss: 0.222829\n",
      "Train Epoch: 101 [260/300 (87%)]\tLoss: 0.116973\n",
      "Train Epoch: 101 [270/300 (90%)]\tLoss: 0.068684\n",
      "Train Epoch: 101 [280/300 (93%)]\tLoss: 0.202980\n",
      "Train Epoch: 101 [290/300 (97%)]\tLoss: 0.224038\n",
      "Train Epoch: 101 [0/300 (0%)]\tLoss: 0.171365\n",
      "Train Epoch: 101 [10/300 (3%)]\tLoss: 0.460507\n",
      "Train Epoch: 101 [20/300 (7%)]\tLoss: 0.115753\n",
      "Train Epoch: 101 [30/300 (10%)]\tLoss: 0.166209\n",
      "Train Epoch: 101 [40/300 (13%)]\tLoss: 0.412850\n",
      "Train Epoch: 101 [50/300 (17%)]\tLoss: 0.193330\n",
      "Train Epoch: 101 [60/300 (20%)]\tLoss: 0.400515\n",
      "Train Epoch: 101 [70/300 (23%)]\tLoss: 0.185662\n",
      "Train Epoch: 101 [80/300 (27%)]\tLoss: 0.137819\n",
      "Train Epoch: 101 [90/300 (30%)]\tLoss: 0.172636\n",
      "Train Epoch: 101 [100/300 (33%)]\tLoss: 0.195898\n",
      "Train Epoch: 101 [110/300 (37%)]\tLoss: 0.032555\n",
      "Train Epoch: 101 [120/300 (40%)]\tLoss: 0.731286\n",
      "Train Epoch: 101 [130/300 (43%)]\tLoss: 0.693531\n",
      "Train Epoch: 101 [140/300 (47%)]\tLoss: 0.679194\n",
      "Train Epoch: 101 [150/300 (50%)]\tLoss: 0.177011\n",
      "Train Epoch: 101 [160/300 (53%)]\tLoss: 0.894585\n",
      "Train Epoch: 101 [170/300 (57%)]\tLoss: 1.299244\n",
      "Train Epoch: 101 [180/300 (60%)]\tLoss: 0.396756\n",
      "Train Epoch: 101 [190/300 (63%)]\tLoss: 0.330047\n",
      "Train Epoch: 101 [200/300 (67%)]\tLoss: 0.032261\n",
      "Train Epoch: 101 [210/300 (70%)]\tLoss: 0.535978\n",
      "Train Epoch: 101 [220/300 (73%)]\tLoss: 0.404140\n",
      "Train Epoch: 101 [230/300 (77%)]\tLoss: 0.138266\n",
      "Train Epoch: 101 [240/300 (80%)]\tLoss: 0.594110\n",
      "Train Epoch: 101 [250/300 (83%)]\tLoss: 0.923690\n",
      "Train Epoch: 101 [260/300 (87%)]\tLoss: 0.390248\n",
      "Train Epoch: 101 [270/300 (90%)]\tLoss: 0.223908\n",
      "Train Epoch: 101 [280/300 (93%)]\tLoss: 0.689782\n",
      "Train Epoch: 101 [290/300 (97%)]\tLoss: 0.515691\n",
      "Train Epoch: 101 [0/300 (0%)]\tLoss: 0.055749\n",
      "Train Epoch: 101 [10/300 (3%)]\tLoss: 0.496789\n",
      "Train Epoch: 101 [20/300 (7%)]\tLoss: 0.063562\n",
      "Train Epoch: 101 [30/300 (10%)]\tLoss: 0.707696\n",
      "Train Epoch: 101 [40/300 (13%)]\tLoss: 0.354339\n",
      "Train Epoch: 101 [50/300 (17%)]\tLoss: 0.185215\n",
      "Train Epoch: 101 [60/300 (20%)]\tLoss: 0.787665\n",
      "Train Epoch: 101 [70/300 (23%)]\tLoss: 0.365033\n",
      "Train Epoch: 101 [80/300 (27%)]\tLoss: 0.658224\n",
      "Train Epoch: 101 [90/300 (30%)]\tLoss: 0.378582\n",
      "Train Epoch: 101 [100/300 (33%)]\tLoss: 0.201493\n",
      "Train Epoch: 101 [110/300 (37%)]\tLoss: 0.402652\n",
      "Train Epoch: 101 [120/300 (40%)]\tLoss: 0.236640\n",
      "Train Epoch: 101 [130/300 (43%)]\tLoss: 0.040487\n",
      "Train Epoch: 101 [140/300 (47%)]\tLoss: 0.755831\n",
      "Train Epoch: 101 [150/300 (50%)]\tLoss: 0.034797\n",
      "Train Epoch: 101 [160/300 (53%)]\tLoss: 0.173113\n",
      "Train Epoch: 101 [170/300 (57%)]\tLoss: 0.048706\n",
      "Train Epoch: 101 [180/300 (60%)]\tLoss: 0.106261\n",
      "Train Epoch: 101 [190/300 (63%)]\tLoss: 0.056824\n",
      "Train Epoch: 101 [200/300 (67%)]\tLoss: 0.029250\n",
      "Train Epoch: 101 [210/300 (70%)]\tLoss: 0.258737\n",
      "Train Epoch: 101 [220/300 (73%)]\tLoss: 0.115971\n",
      "Train Epoch: 101 [230/300 (77%)]\tLoss: 0.091051\n",
      "Train Epoch: 101 [240/300 (80%)]\tLoss: 0.100853\n",
      "Train Epoch: 101 [250/300 (83%)]\tLoss: 0.050143\n",
      "Train Epoch: 101 [260/300 (87%)]\tLoss: 0.040257\n",
      "Train Epoch: 101 [270/300 (90%)]\tLoss: 0.126799\n",
      "Train Epoch: 101 [280/300 (93%)]\tLoss: 0.287004\n",
      "Train Epoch: 101 [290/300 (97%)]\tLoss: 0.547903\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9650/10000 (96%)\n",
      "\n",
      "Successfully pushed server data to victoria metrics\n",
      "Round 100 finished\n",
      "Round 101 finished\n",
      "Round 102 finished\n",
      "Round 103 finished\n",
      "Round 104 finished\n",
      "Round 105 finished\n",
      "Round 106 finished\n",
      "Round 107 finished\n",
      "Round 108 finished\n",
      "Round 109 finished\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9671/10000 (97%)\n",
      "\n",
      "Successfully pushed server data to victoria metrics\n",
      "Round 110 finished\n",
      "Round 111 finished\n",
      "Round 112 finished\n",
      "Round 113 finished\n",
      "Round 114 finished\n",
      "Round 115 finished\n",
      "Round 116 finished\n",
      "Round 117 finished\n",
      "Round 118 finished\n",
      "Round 119 finished\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9656/10000 (97%)\n",
      "\n",
      "Successfully pushed server data to victoria metrics\n",
      "Round 120 finished\n",
      "Round 121 finished\n",
      "Round 122 finished\n",
      "Round 123 finished\n",
      "Round 124 finished\n",
      "Round 125 finished\n",
      "Round 126 finished\n",
      "Round 127 finished\n",
      "Round 128 finished\n",
      "Round 129 finished\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9685/10000 (97%)\n",
      "\n",
      "Successfully pushed server data to victoria metrics\n",
      "Round 130 finished\n",
      "Round 131 finished\n",
      "Round 132 finished\n",
      "Round 133 finished\n",
      "Round 134 finished\n",
      "Round 135 finished\n",
      "Round 136 finished\n",
      "Round 137 finished\n",
      "Round 138 finished\n",
      "Round 139 finished\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9688/10000 (97%)\n",
      "\n",
      "Successfully pushed server data to victoria metrics\n",
      "Round 140 finished\n",
      "Round 141 finished\n",
      "Round 142 finished\n",
      "Round 143 finished\n",
      "Round 144 finished\n",
      "Round 145 finished\n",
      "Round 146 finished\n",
      "Round 147 finished\n",
      "Round 148 finished\n",
      "Model aggregation in round 150 was successful\n",
      "Round 149 finished\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9722/10000 (97%)\n",
      "\n",
      "Successfully pushed server data to victoria metrics\n",
      "Round 150 finished\n",
      "Round 151 finished\n",
      "Round 152 finished\n",
      "Round 153 finished\n",
      "Round 154 finished\n",
      "Round 155 finished\n",
      "Round 156 finished\n",
      "Round 157 finished\n",
      "Round 158 finished\n",
      "Round 159 finished\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9730/10000 (97%)\n",
      "\n",
      "Successfully pushed server data to victoria metrics\n",
      "Round 160 finished\n",
      "Round 161 finished\n",
      "Round 162 finished\n",
      "Round 163 finished\n",
      "Round 164 finished\n",
      "Round 165 finished\n",
      "Round 166 finished\n",
      "Round 167 finished\n",
      "Round 168 finished\n",
      "Round 169 finished\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9733/10000 (97%)\n",
      "\n",
      "Successfully pushed server data to victoria metrics\n",
      "Round 170 finished\n",
      "Round 171 finished\n",
      "Round 172 finished\n",
      "Round 173 finished\n",
      "Round 174 finished\n",
      "Round 175 finished\n",
      "Round 176 finished\n",
      "Round 177 finished\n",
      "Round 178 finished\n",
      "Round 179 finished\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9742/10000 (97%)\n",
      "\n",
      "Successfully pushed server data to victoria metrics\n",
      "Round 180 finished\n",
      "Round 181 finished\n",
      "Round 182 finished\n",
      "Round 183 finished\n",
      "Round 184 finished\n",
      "Round 185 finished\n",
      "Round 186 finished\n",
      "Round 187 finished\n",
      "Round 188 finished\n",
      "Round 189 finished\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9761/10000 (98%)\n",
      "\n",
      "Successfully pushed server data to victoria metrics\n",
      "Round 190 finished\n",
      "Round 191 finished\n",
      "Round 192 finished\n",
      "Round 193 finished\n",
      "Round 194 finished\n",
      "Round 195 finished\n",
      "Round 196 finished\n",
      "Round 197 finished\n",
      "Round 198 finished\n",
      "Model aggregation in round 200 was successful\n",
      "Round 199 finished\n",
      "Train Epoch: 201 [0/300 (0%)]\tLoss: 0.014268\n",
      "Train Epoch: 201 [10/300 (3%)]\tLoss: 0.282040\n",
      "Train Epoch: 201 [20/300 (7%)]\tLoss: 0.242793\n",
      "Train Epoch: 201 [30/300 (10%)]\tLoss: 0.268087\n",
      "Train Epoch: 201 [40/300 (13%)]\tLoss: 0.788523\n",
      "Train Epoch: 201 [50/300 (17%)]\tLoss: 0.224045\n",
      "Train Epoch: 201 [60/300 (20%)]\tLoss: 0.389333\n",
      "Train Epoch: 201 [70/300 (23%)]\tLoss: 0.367169\n",
      "Train Epoch: 201 [80/300 (27%)]\tLoss: 0.116930\n",
      "Train Epoch: 201 [90/300 (30%)]\tLoss: 0.068754\n",
      "Train Epoch: 201 [100/300 (33%)]\tLoss: 0.357466\n",
      "Train Epoch: 201 [110/300 (37%)]\tLoss: 0.767770\n",
      "Train Epoch: 201 [120/300 (40%)]\tLoss: 0.780823\n",
      "Train Epoch: 201 [130/300 (43%)]\tLoss: 0.677311\n",
      "Train Epoch: 201 [140/300 (47%)]\tLoss: 0.308847\n",
      "Train Epoch: 201 [150/300 (50%)]\tLoss: 0.130205\n",
      "Train Epoch: 201 [160/300 (53%)]\tLoss: 0.134877\n",
      "Train Epoch: 201 [170/300 (57%)]\tLoss: 0.228211\n",
      "Train Epoch: 201 [180/300 (60%)]\tLoss: 0.638093\n",
      "Train Epoch: 201 [190/300 (63%)]\tLoss: 0.190229\n",
      "Train Epoch: 201 [200/300 (67%)]\tLoss: 0.036765\n",
      "Train Epoch: 201 [210/300 (70%)]\tLoss: 0.511697\n",
      "Train Epoch: 201 [220/300 (73%)]\tLoss: 0.991741\n",
      "Train Epoch: 201 [230/300 (77%)]\tLoss: 0.801390\n",
      "Train Epoch: 201 [240/300 (80%)]\tLoss: 0.183443\n",
      "Train Epoch: 201 [250/300 (83%)]\tLoss: 0.213763\n",
      "Train Epoch: 201 [260/300 (87%)]\tLoss: 0.244242\n",
      "Train Epoch: 201 [270/300 (90%)]\tLoss: 0.584454\n",
      "Train Epoch: 201 [280/300 (93%)]\tLoss: 0.060920\n",
      "Train Epoch: 201 [290/300 (97%)]\tLoss: 0.006477\n",
      "Train Epoch: 201 [0/300 (0%)]\tLoss: 0.393745\n",
      "Train Epoch: 201 [10/300 (3%)]\tLoss: 0.085201\n",
      "Train Epoch: 201 [20/300 (7%)]\tLoss: 0.283345\n",
      "Train Epoch: 201 [30/300 (10%)]\tLoss: 0.639856\n",
      "Train Epoch: 201 [40/300 (13%)]\tLoss: 0.166949\n",
      "Train Epoch: 201 [50/300 (17%)]\tLoss: 0.175545\n",
      "Train Epoch: 201 [60/300 (20%)]\tLoss: 0.040851\n",
      "Train Epoch: 201 [70/300 (23%)]\tLoss: 0.419752\n",
      "Train Epoch: 201 [80/300 (27%)]\tLoss: 0.486708\n",
      "Train Epoch: 201 [90/300 (30%)]\tLoss: 0.056383\n",
      "Train Epoch: 201 [100/300 (33%)]\tLoss: 0.143104\n",
      "Train Epoch: 201 [110/300 (37%)]\tLoss: 0.238335\n",
      "Train Epoch: 201 [120/300 (40%)]\tLoss: 0.806039\n",
      "Train Epoch: 201 [130/300 (43%)]\tLoss: 0.101689\n",
      "Train Epoch: 201 [140/300 (47%)]\tLoss: 0.238065\n",
      "Train Epoch: 201 [150/300 (50%)]\tLoss: 0.091094\n",
      "Train Epoch: 201 [160/300 (53%)]\tLoss: 0.552745\n",
      "Train Epoch: 201 [170/300 (57%)]\tLoss: 0.143169\n",
      "Train Epoch: 201 [180/300 (60%)]\tLoss: 0.096769\n",
      "Train Epoch: 201 [190/300 (63%)]\tLoss: 0.089331\n",
      "Train Epoch: 201 [200/300 (67%)]\tLoss: 0.310409\n",
      "Train Epoch: 201 [210/300 (70%)]\tLoss: 0.496014\n",
      "Train Epoch: 201 [220/300 (73%)]\tLoss: 0.227751\n",
      "Train Epoch: 201 [230/300 (77%)]\tLoss: 0.044612\n",
      "Train Epoch: 201 [240/300 (80%)]\tLoss: 0.247182\n",
      "Train Epoch: 201 [250/300 (83%)]\tLoss: 0.033721\n",
      "Train Epoch: 201 [260/300 (87%)]\tLoss: 0.353506\n",
      "Train Epoch: 201 [270/300 (90%)]\tLoss: 0.169209\n",
      "Train Epoch: 201 [280/300 (93%)]\tLoss: 0.324660\n",
      "Train Epoch: 201 [290/300 (97%)]\tLoss: 0.513699\n",
      "Train Epoch: 201 [0/300 (0%)]\tLoss: 0.025921\n",
      "Train Epoch: 201 [10/300 (3%)]\tLoss: 0.441768\n",
      "Train Epoch: 201 [20/300 (7%)]\tLoss: 0.135160\n",
      "Train Epoch: 201 [30/300 (10%)]\tLoss: 0.083637\n",
      "Train Epoch: 201 [40/300 (13%)]\tLoss: 1.238842\n",
      "Train Epoch: 201 [50/300 (17%)]\tLoss: 0.100654\n",
      "Train Epoch: 201 [60/300 (20%)]\tLoss: 0.236809\n",
      "Train Epoch: 201 [70/300 (23%)]\tLoss: 0.054775\n",
      "Train Epoch: 201 [80/300 (27%)]\tLoss: 0.220295\n",
      "Train Epoch: 201 [90/300 (30%)]\tLoss: 0.112954\n",
      "Train Epoch: 201 [100/300 (33%)]\tLoss: 0.157138\n",
      "Train Epoch: 201 [110/300 (37%)]\tLoss: 0.082339\n",
      "Train Epoch: 201 [120/300 (40%)]\tLoss: 0.184298\n",
      "Train Epoch: 201 [130/300 (43%)]\tLoss: 0.206521\n",
      "Train Epoch: 201 [140/300 (47%)]\tLoss: 0.067811\n",
      "Train Epoch: 201 [150/300 (50%)]\tLoss: 0.112308\n",
      "Train Epoch: 201 [160/300 (53%)]\tLoss: 0.282060\n",
      "Train Epoch: 201 [170/300 (57%)]\tLoss: 1.427593\n",
      "Train Epoch: 201 [180/300 (60%)]\tLoss: 0.992850\n",
      "Train Epoch: 201 [190/300 (63%)]\tLoss: 0.506773\n",
      "Train Epoch: 201 [200/300 (67%)]\tLoss: 0.296430\n",
      "Train Epoch: 201 [210/300 (70%)]\tLoss: 0.235656\n",
      "Train Epoch: 201 [220/300 (73%)]\tLoss: 0.123481\n",
      "Train Epoch: 201 [230/300 (77%)]\tLoss: 0.152735\n",
      "Train Epoch: 201 [240/300 (80%)]\tLoss: 0.139247\n",
      "Train Epoch: 201 [250/300 (83%)]\tLoss: 0.021943\n",
      "Train Epoch: 201 [260/300 (87%)]\tLoss: 0.484437\n",
      "Train Epoch: 201 [270/300 (90%)]\tLoss: 0.460230\n",
      "Train Epoch: 201 [280/300 (93%)]\tLoss: 0.267689\n",
      "Train Epoch: 201 [290/300 (97%)]\tLoss: 0.222559\n",
      "Train Epoch: 201 [0/300 (0%)]\tLoss: 0.118250\n",
      "Train Epoch: 201 [10/300 (3%)]\tLoss: 0.870759\n",
      "Train Epoch: 201 [20/300 (7%)]\tLoss: 0.176763\n",
      "Train Epoch: 201 [30/300 (10%)]\tLoss: 0.192909\n",
      "Train Epoch: 201 [40/300 (13%)]\tLoss: 0.035114\n",
      "Train Epoch: 201 [50/300 (17%)]\tLoss: 0.070301\n",
      "Train Epoch: 201 [60/300 (20%)]\tLoss: 0.200170\n",
      "Train Epoch: 201 [70/300 (23%)]\tLoss: 0.124538\n",
      "Train Epoch: 201 [80/300 (27%)]\tLoss: 0.778734\n",
      "Train Epoch: 201 [90/300 (30%)]\tLoss: 0.037266\n",
      "Train Epoch: 201 [100/300 (33%)]\tLoss: 0.002572\n",
      "Train Epoch: 201 [110/300 (37%)]\tLoss: 0.282717\n",
      "Train Epoch: 201 [120/300 (40%)]\tLoss: 0.202075\n",
      "Train Epoch: 201 [130/300 (43%)]\tLoss: 0.509012\n",
      "Train Epoch: 201 [140/300 (47%)]\tLoss: 0.041061\n",
      "Train Epoch: 201 [150/300 (50%)]\tLoss: 0.945960\n",
      "Train Epoch: 201 [160/300 (53%)]\tLoss: 0.427703\n",
      "Train Epoch: 201 [170/300 (57%)]\tLoss: 0.214046\n",
      "Train Epoch: 201 [180/300 (60%)]\tLoss: 0.085735\n",
      "Train Epoch: 201 [190/300 (63%)]\tLoss: 0.126869\n",
      "Train Epoch: 201 [200/300 (67%)]\tLoss: 0.055867\n",
      "Train Epoch: 201 [210/300 (70%)]\tLoss: 0.269175\n",
      "Train Epoch: 201 [220/300 (73%)]\tLoss: 0.167582\n",
      "Train Epoch: 201 [230/300 (77%)]\tLoss: 0.035296\n",
      "Train Epoch: 201 [240/300 (80%)]\tLoss: 0.025214\n",
      "Train Epoch: 201 [250/300 (83%)]\tLoss: 0.166536\n",
      "Train Epoch: 201 [260/300 (87%)]\tLoss: 1.021312\n",
      "Train Epoch: 201 [270/300 (90%)]\tLoss: 0.299067\n",
      "Train Epoch: 201 [280/300 (93%)]\tLoss: 0.052835\n",
      "Train Epoch: 201 [290/300 (97%)]\tLoss: 0.074077\n",
      "Train Epoch: 201 [0/300 (0%)]\tLoss: 0.086446\n",
      "Train Epoch: 201 [10/300 (3%)]\tLoss: 0.493506\n",
      "Train Epoch: 201 [20/300 (7%)]\tLoss: 0.021400\n",
      "Train Epoch: 201 [30/300 (10%)]\tLoss: 0.238547\n",
      "Train Epoch: 201 [40/300 (13%)]\tLoss: 0.081022\n",
      "Train Epoch: 201 [50/300 (17%)]\tLoss: 0.323440\n",
      "Train Epoch: 201 [60/300 (20%)]\tLoss: 0.110007\n",
      "Train Epoch: 201 [70/300 (23%)]\tLoss: 0.177595\n",
      "Train Epoch: 201 [80/300 (27%)]\tLoss: 0.060812\n",
      "Train Epoch: 201 [90/300 (30%)]\tLoss: 0.128327\n",
      "Train Epoch: 201 [100/300 (33%)]\tLoss: 0.204964\n",
      "Train Epoch: 201 [110/300 (37%)]\tLoss: 0.269601\n",
      "Train Epoch: 201 [120/300 (40%)]\tLoss: 0.285500\n",
      "Train Epoch: 201 [130/300 (43%)]\tLoss: 0.753938\n",
      "Train Epoch: 201 [140/300 (47%)]\tLoss: 0.948462\n",
      "Train Epoch: 201 [150/300 (50%)]\tLoss: 0.075852\n",
      "Train Epoch: 201 [160/300 (53%)]\tLoss: 0.514044\n",
      "Train Epoch: 201 [170/300 (57%)]\tLoss: 0.371587\n",
      "Train Epoch: 201 [180/300 (60%)]\tLoss: 0.379274\n",
      "Train Epoch: 201 [190/300 (63%)]\tLoss: 0.075815\n",
      "Train Epoch: 201 [200/300 (67%)]\tLoss: 0.203286\n",
      "Train Epoch: 201 [210/300 (70%)]\tLoss: 0.435969\n",
      "Train Epoch: 201 [220/300 (73%)]\tLoss: 0.328326\n",
      "Train Epoch: 201 [230/300 (77%)]\tLoss: 0.075003\n",
      "Train Epoch: 201 [240/300 (80%)]\tLoss: 0.113461\n",
      "Train Epoch: 201 [250/300 (83%)]\tLoss: 0.312044\n",
      "Train Epoch: 201 [260/300 (87%)]\tLoss: 0.247708\n",
      "Train Epoch: 201 [270/300 (90%)]\tLoss: 0.308306\n",
      "Train Epoch: 201 [280/300 (93%)]\tLoss: 0.367936\n",
      "Train Epoch: 201 [290/300 (97%)]\tLoss: 0.277990\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9766/10000 (98%)\n",
      "\n",
      "Successfully pushed server data to victoria metrics\n",
      "Round 200 finished\n",
      "Load default model successfully\n",
      "20/200 clients cleaned\n",
      "40/200 clients cleaned\n",
      "60/200 clients cleaned\n",
      "80/200 clients cleaned\n",
      "100/200 clients cleaned\n",
      "120/200 clients cleaned\n",
      "140/200 clients cleaned\n",
      "160/200 clients cleaned\n",
      "180/200 clients cleaned\n",
      "200/200 clients cleaned\n",
      "Cleaning successfully\n",
      "Poison 10/200 clients\n",
      "Flip 100.0% of the 5 labels to 4\n",
      "[103 135  82  52 189 152 130 155 176 118]\n",
      "Round 1 finished\n",
      "Round 2 finished\n",
      "Round 3 finished\n",
      "Round 4 finished\n",
      "Round 5 finished\n",
      "Round 6 finished\n",
      "Round 7 finished\n",
      "Round 8 finished\n",
      "Round 9 finished\n",
      "\n",
      "Test set: Average loss: 0.0011, Accuracy: 8186/10000 (82%)\n",
      "\n",
      "Successfully pushed server data to victoria metrics\n",
      "Round 10 finished\n",
      "Round 11 finished\n",
      "Round 12 finished\n",
      "Round 13 finished\n",
      "Round 14 finished\n",
      "Round 15 finished\n",
      "Round 16 finished\n",
      "Round 17 finished\n",
      "Round 18 finished\n",
      "Round 19 finished\n",
      "\n",
      "Test set: Average loss: 0.0006, Accuracy: 9078/10000 (91%)\n",
      "\n",
      "Successfully pushed server data to victoria metrics\n",
      "Round 20 finished\n",
      "Round 21 finished\n",
      "Round 22 finished\n",
      "Round 23 finished\n",
      "Round 24 finished\n",
      "Round 25 finished\n",
      "Round 26 finished\n",
      "Round 27 finished\n",
      "Round 28 finished\n",
      "Round 29 finished\n",
      "\n",
      "Test set: Average loss: 0.0004, Accuracy: 9267/10000 (93%)\n",
      "\n",
      "Successfully pushed server data to victoria metrics\n",
      "Round 30 finished\n",
      "Round 31 finished\n",
      "Round 32 finished\n",
      "Round 33 finished\n",
      "Round 34 finished\n",
      "Round 35 finished\n",
      "Round 36 finished\n",
      "Round 37 finished\n",
      "Round 38 finished\n",
      "Round 39 finished\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 9404/10000 (94%)\n",
      "\n",
      "Successfully pushed server data to victoria metrics\n",
      "Round 40 finished\n",
      "Round 41 finished\n",
      "Round 42 finished\n",
      "Round 43 finished\n",
      "Round 44 finished\n",
      "Round 45 finished\n",
      "Round 46 finished\n",
      "Round 47 finished\n",
      "Round 48 finished\n",
      "Model aggregation in round 50 was successful\n",
      "Round 49 finished\n",
      "\n",
      "Test set: Average loss: 0.0002, Accuracy: 9451/10000 (95%)\n",
      "\n",
      "Successfully pushed server data to victoria metrics\n",
      "Round 50 finished\n",
      "Round 51 finished\n",
      "Round 52 finished\n",
      "Round 53 finished\n",
      "Round 54 finished\n",
      "Round 55 finished\n",
      "Round 56 finished\n",
      "Round 57 finished\n",
      "Round 58 finished\n",
      "Round 59 finished\n",
      "\n",
      "Test set: Average loss: 0.0002, Accuracy: 9527/10000 (95%)\n",
      "\n",
      "Successfully pushed server data to victoria metrics\n",
      "Round 60 finished\n",
      "Round 61 finished\n",
      "Round 62 finished\n",
      "Round 63 finished\n",
      "Round 64 finished\n",
      "Round 65 finished\n",
      "Round 66 finished\n",
      "Round 67 finished\n",
      "Round 68 finished\n",
      "Round 69 finished\n",
      "\n",
      "Test set: Average loss: 0.0002, Accuracy: 9560/10000 (96%)\n",
      "\n",
      "Successfully pushed server data to victoria metrics\n",
      "Round 70 finished\n",
      "Round 71 finished\n",
      "Round 72 finished\n",
      "Round 73 finished\n",
      "Round 74 finished\n",
      "Round 75 finished\n",
      "Round 76 finished\n",
      "Round 77 finished\n",
      "Round 78 finished\n",
      "Round 79 finished\n",
      "\n",
      "Test set: Average loss: 0.0002, Accuracy: 9601/10000 (96%)\n",
      "\n",
      "Successfully pushed server data to victoria metrics\n",
      "Round 80 finished\n",
      "Round 81 finished\n",
      "Round 82 finished\n",
      "Round 83 finished\n",
      "Round 84 finished\n",
      "Round 85 finished\n",
      "Round 86 finished\n",
      "Round 87 finished\n",
      "Round 88 finished\n",
      "Round 89 finished\n",
      "\n",
      "Test set: Average loss: 0.0002, Accuracy: 9585/10000 (96%)\n",
      "\n",
      "Successfully pushed server data to victoria metrics\n",
      "Round 90 finished\n",
      "Round 91 finished\n",
      "Round 92 finished\n",
      "Round 93 finished\n",
      "Round 94 finished\n",
      "Round 95 finished\n",
      "Round 96 finished\n",
      "Round 97 finished\n",
      "Round 98 finished\n",
      "Model aggregation in round 100 was successful\n",
      "Round 99 finished\n",
      "Train Epoch: 101 [0/300 (0%)]\tLoss: 0.658824\n",
      "Train Epoch: 101 [10/300 (3%)]\tLoss: 0.230473\n",
      "Train Epoch: 101 [20/300 (7%)]\tLoss: 0.283649\n",
      "Train Epoch: 101 [30/300 (10%)]\tLoss: 0.713487\n",
      "Train Epoch: 101 [40/300 (13%)]\tLoss: 0.047207\n",
      "Train Epoch: 101 [50/300 (17%)]\tLoss: 0.020554\n",
      "Train Epoch: 101 [60/300 (20%)]\tLoss: 0.263413\n",
      "Train Epoch: 101 [70/300 (23%)]\tLoss: 0.200731\n",
      "Train Epoch: 101 [80/300 (27%)]\tLoss: 0.467590\n",
      "Train Epoch: 101 [90/300 (30%)]\tLoss: 0.156070\n",
      "Train Epoch: 101 [100/300 (33%)]\tLoss: 0.162908\n",
      "Train Epoch: 101 [110/300 (37%)]\tLoss: 0.086570\n",
      "Train Epoch: 101 [120/300 (40%)]\tLoss: 0.089923\n",
      "Train Epoch: 101 [130/300 (43%)]\tLoss: 0.603182\n",
      "Train Epoch: 101 [140/300 (47%)]\tLoss: 0.268413\n",
      "Train Epoch: 101 [150/300 (50%)]\tLoss: 0.574411\n",
      "Train Epoch: 101 [160/300 (53%)]\tLoss: 0.458231\n",
      "Train Epoch: 101 [170/300 (57%)]\tLoss: 0.173873\n",
      "Train Epoch: 101 [180/300 (60%)]\tLoss: 0.219848\n",
      "Train Epoch: 101 [190/300 (63%)]\tLoss: 0.172286\n",
      "Train Epoch: 101 [200/300 (67%)]\tLoss: 0.321512\n",
      "Train Epoch: 101 [210/300 (70%)]\tLoss: 0.245290\n",
      "Train Epoch: 101 [220/300 (73%)]\tLoss: 0.098881\n",
      "Train Epoch: 101 [230/300 (77%)]\tLoss: 0.029517\n",
      "Train Epoch: 101 [240/300 (80%)]\tLoss: 0.327456\n",
      "Train Epoch: 101 [250/300 (83%)]\tLoss: 0.782508\n",
      "Train Epoch: 101 [260/300 (87%)]\tLoss: 0.447289\n",
      "Train Epoch: 101 [270/300 (90%)]\tLoss: 0.317691\n",
      "Train Epoch: 101 [280/300 (93%)]\tLoss: 0.251020\n",
      "Train Epoch: 101 [290/300 (97%)]\tLoss: 0.643132\n",
      "Train Epoch: 101 [0/300 (0%)]\tLoss: 0.226001\n",
      "Train Epoch: 101 [10/300 (3%)]\tLoss: 0.082021\n",
      "Train Epoch: 101 [20/300 (7%)]\tLoss: 1.143191\n",
      "Train Epoch: 101 [30/300 (10%)]\tLoss: 0.144009\n",
      "Train Epoch: 101 [40/300 (13%)]\tLoss: 0.045821\n",
      "Train Epoch: 101 [50/300 (17%)]\tLoss: 0.649453\n",
      "Train Epoch: 101 [60/300 (20%)]\tLoss: 0.180960\n",
      "Train Epoch: 101 [70/300 (23%)]\tLoss: 0.136355\n",
      "Train Epoch: 101 [80/300 (27%)]\tLoss: 0.193172\n",
      "Train Epoch: 101 [90/300 (30%)]\tLoss: 0.135532\n",
      "Train Epoch: 101 [100/300 (33%)]\tLoss: 0.090167\n",
      "Train Epoch: 101 [110/300 (37%)]\tLoss: 0.883442\n",
      "Train Epoch: 101 [120/300 (40%)]\tLoss: 0.520320\n",
      "Train Epoch: 101 [130/300 (43%)]\tLoss: 0.550276\n",
      "Train Epoch: 101 [140/300 (47%)]\tLoss: 0.055146\n",
      "Train Epoch: 101 [150/300 (50%)]\tLoss: 0.712198\n",
      "Train Epoch: 101 [160/300 (53%)]\tLoss: 0.310386\n",
      "Train Epoch: 101 [170/300 (57%)]\tLoss: 0.048185\n",
      "Train Epoch: 101 [180/300 (60%)]\tLoss: 0.821537\n",
      "Train Epoch: 101 [190/300 (63%)]\tLoss: 0.166330\n",
      "Train Epoch: 101 [200/300 (67%)]\tLoss: 0.163484\n",
      "Train Epoch: 101 [210/300 (70%)]\tLoss: 0.172465\n",
      "Train Epoch: 101 [220/300 (73%)]\tLoss: 0.200289\n",
      "Train Epoch: 101 [230/300 (77%)]\tLoss: 0.671460\n",
      "Train Epoch: 101 [240/300 (80%)]\tLoss: 0.758548\n",
      "Train Epoch: 101 [250/300 (83%)]\tLoss: 0.330606\n",
      "Train Epoch: 101 [260/300 (87%)]\tLoss: 0.175504\n",
      "Train Epoch: 101 [270/300 (90%)]\tLoss: 0.320141\n",
      "Train Epoch: 101 [280/300 (93%)]\tLoss: 0.066217\n",
      "Train Epoch: 101 [290/300 (97%)]\tLoss: 0.352804\n",
      "Train Epoch: 101 [0/300 (0%)]\tLoss: 0.854056\n",
      "Train Epoch: 101 [10/300 (3%)]\tLoss: 1.147192\n",
      "Train Epoch: 101 [20/300 (7%)]\tLoss: 0.477152\n",
      "Train Epoch: 101 [30/300 (10%)]\tLoss: 0.116023\n",
      "Train Epoch: 101 [40/300 (13%)]\tLoss: 0.135178\n",
      "Train Epoch: 101 [50/300 (17%)]\tLoss: 0.498304\n",
      "Train Epoch: 101 [60/300 (20%)]\tLoss: 0.676894\n",
      "Train Epoch: 101 [70/300 (23%)]\tLoss: 0.244159\n",
      "Train Epoch: 101 [80/300 (27%)]\tLoss: 0.992599\n",
      "Train Epoch: 101 [90/300 (30%)]\tLoss: 0.316287\n",
      "Train Epoch: 101 [100/300 (33%)]\tLoss: 0.252608\n",
      "Train Epoch: 101 [110/300 (37%)]\tLoss: 0.064449\n",
      "Train Epoch: 101 [120/300 (40%)]\tLoss: 1.586042\n",
      "Train Epoch: 101 [130/300 (43%)]\tLoss: 0.222737\n",
      "Train Epoch: 101 [140/300 (47%)]\tLoss: 0.430784\n",
      "Train Epoch: 101 [150/300 (50%)]\tLoss: 1.454645\n",
      "Train Epoch: 101 [160/300 (53%)]\tLoss: 0.124567\n",
      "Train Epoch: 101 [170/300 (57%)]\tLoss: 0.023026\n",
      "Train Epoch: 101 [180/300 (60%)]\tLoss: 0.389074\n",
      "Train Epoch: 101 [190/300 (63%)]\tLoss: 0.325145\n",
      "Train Epoch: 101 [200/300 (67%)]\tLoss: 0.056463\n",
      "Train Epoch: 101 [210/300 (70%)]\tLoss: 0.107635\n",
      "Train Epoch: 101 [220/300 (73%)]\tLoss: 0.183083\n",
      "Train Epoch: 101 [230/300 (77%)]\tLoss: 0.064875\n",
      "Train Epoch: 101 [240/300 (80%)]\tLoss: 0.193177\n",
      "Train Epoch: 101 [250/300 (83%)]\tLoss: 0.047698\n",
      "Train Epoch: 101 [260/300 (87%)]\tLoss: 0.218774\n",
      "Train Epoch: 101 [270/300 (90%)]\tLoss: 0.082288\n",
      "Train Epoch: 101 [280/300 (93%)]\tLoss: 0.111492\n",
      "Train Epoch: 101 [290/300 (97%)]\tLoss: 0.073309\n",
      "Train Epoch: 101 [0/300 (0%)]\tLoss: 0.733344\n",
      "Train Epoch: 101 [10/300 (3%)]\tLoss: 0.666510\n",
      "Train Epoch: 101 [20/300 (7%)]\tLoss: 0.598636\n",
      "Train Epoch: 101 [30/300 (10%)]\tLoss: 0.466689\n",
      "Train Epoch: 101 [40/300 (13%)]\tLoss: 0.368693\n",
      "Train Epoch: 101 [50/300 (17%)]\tLoss: 0.246734\n",
      "Train Epoch: 101 [60/300 (20%)]\tLoss: 0.153640\n",
      "Train Epoch: 101 [70/300 (23%)]\tLoss: 0.466842\n",
      "Train Epoch: 101 [80/300 (27%)]\tLoss: 1.335788\n",
      "Train Epoch: 101 [90/300 (30%)]\tLoss: 0.174426\n",
      "Train Epoch: 101 [100/300 (33%)]\tLoss: 0.186413\n",
      "Train Epoch: 101 [110/300 (37%)]\tLoss: 0.623379\n",
      "Train Epoch: 101 [120/300 (40%)]\tLoss: 0.380970\n",
      "Train Epoch: 101 [130/300 (43%)]\tLoss: 0.152588\n",
      "Train Epoch: 101 [140/300 (47%)]\tLoss: 0.395512\n",
      "Train Epoch: 101 [150/300 (50%)]\tLoss: 0.162661\n",
      "Train Epoch: 101 [160/300 (53%)]\tLoss: 0.339719\n",
      "Train Epoch: 101 [170/300 (57%)]\tLoss: 0.497438\n",
      "Train Epoch: 101 [180/300 (60%)]\tLoss: 0.566562\n",
      "Train Epoch: 101 [190/300 (63%)]\tLoss: 0.321210\n",
      "Train Epoch: 101 [200/300 (67%)]\tLoss: 0.124949\n",
      "Train Epoch: 101 [210/300 (70%)]\tLoss: 0.482738\n",
      "Train Epoch: 101 [220/300 (73%)]\tLoss: 0.300067\n",
      "Train Epoch: 101 [230/300 (77%)]\tLoss: 0.912491\n",
      "Train Epoch: 101 [240/300 (80%)]\tLoss: 0.476356\n",
      "Train Epoch: 101 [250/300 (83%)]\tLoss: 0.416563\n",
      "Train Epoch: 101 [260/300 (87%)]\tLoss: 0.536238\n",
      "Train Epoch: 101 [270/300 (90%)]\tLoss: 0.200486\n",
      "Train Epoch: 101 [280/300 (93%)]\tLoss: 1.192893\n",
      "Train Epoch: 101 [290/300 (97%)]\tLoss: 0.445780\n",
      "Train Epoch: 101 [0/300 (0%)]\tLoss: 0.642627\n",
      "Train Epoch: 101 [10/300 (3%)]\tLoss: 0.387849\n",
      "Train Epoch: 101 [20/300 (7%)]\tLoss: 0.254517\n",
      "Train Epoch: 101 [30/300 (10%)]\tLoss: 0.134052\n",
      "Train Epoch: 101 [40/300 (13%)]\tLoss: 0.065773\n",
      "Train Epoch: 101 [50/300 (17%)]\tLoss: 0.448247\n",
      "Train Epoch: 101 [60/300 (20%)]\tLoss: 0.234395\n",
      "Train Epoch: 101 [70/300 (23%)]\tLoss: 0.333835\n",
      "Train Epoch: 101 [80/300 (27%)]\tLoss: 0.227146\n",
      "Train Epoch: 101 [90/300 (30%)]\tLoss: 0.367890\n",
      "Train Epoch: 101 [100/300 (33%)]\tLoss: 0.383614\n",
      "Train Epoch: 101 [110/300 (37%)]\tLoss: 0.060549\n",
      "Train Epoch: 101 [120/300 (40%)]\tLoss: 0.125782\n",
      "Train Epoch: 101 [130/300 (43%)]\tLoss: 0.153902\n",
      "Train Epoch: 101 [140/300 (47%)]\tLoss: 0.813901\n",
      "Train Epoch: 101 [150/300 (50%)]\tLoss: 0.311655\n",
      "Train Epoch: 101 [160/300 (53%)]\tLoss: 0.106749\n",
      "Train Epoch: 101 [170/300 (57%)]\tLoss: 0.264675\n",
      "Train Epoch: 101 [180/300 (60%)]\tLoss: 0.400544\n",
      "Train Epoch: 101 [190/300 (63%)]\tLoss: 0.175841\n",
      "Train Epoch: 101 [200/300 (67%)]\tLoss: 0.654184\n",
      "Train Epoch: 101 [210/300 (70%)]\tLoss: 0.551839\n",
      "Train Epoch: 101 [220/300 (73%)]\tLoss: 0.207707\n",
      "Train Epoch: 101 [230/300 (77%)]\tLoss: 0.307135\n",
      "Train Epoch: 101 [240/300 (80%)]\tLoss: 0.199746\n",
      "Train Epoch: 101 [250/300 (83%)]\tLoss: 0.004752\n",
      "Train Epoch: 101 [260/300 (87%)]\tLoss: 0.005324\n",
      "Train Epoch: 101 [270/300 (90%)]\tLoss: 0.054496\n",
      "Train Epoch: 101 [280/300 (93%)]\tLoss: 0.111063\n",
      "Train Epoch: 101 [290/300 (97%)]\tLoss: 0.130424\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9660/10000 (97%)\n",
      "\n",
      "Successfully pushed server data to victoria metrics\n",
      "Round 100 finished\n",
      "Round 101 finished\n",
      "Round 102 finished\n",
      "Round 103 finished\n",
      "Round 104 finished\n",
      "Round 105 finished\n",
      "Round 106 finished\n",
      "Round 107 finished\n",
      "Round 108 finished\n",
      "Round 109 finished\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9689/10000 (97%)\n",
      "\n",
      "Successfully pushed server data to victoria metrics\n",
      "Round 110 finished\n",
      "Round 111 finished\n",
      "Round 112 finished\n",
      "Round 113 finished\n",
      "Round 114 finished\n",
      "Round 115 finished\n",
      "Round 116 finished\n",
      "Round 117 finished\n",
      "Round 118 finished\n",
      "Round 119 finished\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9698/10000 (97%)\n",
      "\n",
      "Successfully pushed server data to victoria metrics\n",
      "Round 120 finished\n",
      "Round 121 finished\n",
      "Round 122 finished\n",
      "Round 123 finished\n",
      "Round 124 finished\n",
      "Round 125 finished\n",
      "Round 126 finished\n",
      "Round 127 finished\n",
      "Round 128 finished\n",
      "Round 129 finished\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9722/10000 (97%)\n",
      "\n",
      "Successfully pushed server data to victoria metrics\n",
      "Round 130 finished\n",
      "Round 131 finished\n",
      "Round 132 finished\n",
      "Round 133 finished\n",
      "Round 134 finished\n",
      "Round 135 finished\n",
      "Round 136 finished\n",
      "Round 137 finished\n",
      "Round 138 finished\n",
      "Round 139 finished\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9715/10000 (97%)\n",
      "\n",
      "Successfully pushed server data to victoria metrics\n",
      "Round 140 finished\n",
      "Round 141 finished\n",
      "Round 142 finished\n",
      "Round 143 finished\n",
      "Round 144 finished\n",
      "Round 145 finished\n",
      "Round 146 finished\n",
      "Round 147 finished\n",
      "Round 148 finished\n",
      "Model aggregation in round 150 was successful\n",
      "Round 149 finished\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9741/10000 (97%)\n",
      "\n",
      "Successfully pushed server data to victoria metrics\n",
      "Round 150 finished\n",
      "Round 151 finished\n",
      "Round 152 finished\n",
      "Round 153 finished\n",
      "Round 154 finished\n",
      "Round 155 finished\n",
      "Round 156 finished\n",
      "Round 157 finished\n",
      "Round 158 finished\n",
      "Round 159 finished\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9752/10000 (98%)\n",
      "\n",
      "Successfully pushed server data to victoria metrics\n",
      "Round 160 finished\n",
      "Round 161 finished\n",
      "Round 162 finished\n",
      "Round 163 finished\n",
      "Round 164 finished\n",
      "Round 165 finished\n",
      "Round 166 finished\n",
      "Round 167 finished\n",
      "Round 168 finished\n",
      "Round 169 finished\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9758/10000 (98%)\n",
      "\n",
      "Successfully pushed server data to victoria metrics\n",
      "Round 170 finished\n",
      "Round 171 finished\n",
      "Round 172 finished\n",
      "Round 173 finished\n",
      "Round 174 finished\n",
      "Round 175 finished\n",
      "Round 176 finished\n",
      "Round 177 finished\n",
      "Round 178 finished\n",
      "Round 179 finished\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9763/10000 (98%)\n",
      "\n",
      "Successfully pushed server data to victoria metrics\n",
      "Round 180 finished\n",
      "Round 181 finished\n",
      "Round 182 finished\n",
      "Round 183 finished\n",
      "Round 184 finished\n",
      "Round 185 finished\n",
      "Round 186 finished\n",
      "Round 187 finished\n",
      "Round 188 finished\n",
      "Round 189 finished\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9773/10000 (98%)\n",
      "\n",
      "Successfully pushed server data to victoria metrics\n",
      "Round 190 finished\n",
      "Round 191 finished\n",
      "Round 192 finished\n",
      "Round 193 finished\n",
      "Round 194 finished\n",
      "Round 195 finished\n",
      "Round 196 finished\n",
      "Round 197 finished\n",
      "Round 198 finished\n",
      "Model aggregation in round 200 was successful\n",
      "Round 199 finished\n",
      "Train Epoch: 201 [0/300 (0%)]\tLoss: 0.082612\n",
      "Train Epoch: 201 [10/300 (3%)]\tLoss: 0.058801\n",
      "Train Epoch: 201 [20/300 (7%)]\tLoss: 0.134155\n",
      "Train Epoch: 201 [30/300 (10%)]\tLoss: 0.551505\n",
      "Train Epoch: 201 [40/300 (13%)]\tLoss: 0.462409\n",
      "Train Epoch: 201 [50/300 (17%)]\tLoss: 0.148733\n",
      "Train Epoch: 201 [60/300 (20%)]\tLoss: 0.195130\n",
      "Train Epoch: 201 [70/300 (23%)]\tLoss: 0.335703\n",
      "Train Epoch: 201 [80/300 (27%)]\tLoss: 0.084967\n",
      "Train Epoch: 201 [90/300 (30%)]\tLoss: 0.202085\n",
      "Train Epoch: 201 [100/300 (33%)]\tLoss: 0.503172\n",
      "Train Epoch: 201 [110/300 (37%)]\tLoss: 0.017599\n",
      "Train Epoch: 201 [120/300 (40%)]\tLoss: 0.044547\n",
      "Train Epoch: 201 [130/300 (43%)]\tLoss: 0.140385\n",
      "Train Epoch: 201 [140/300 (47%)]\tLoss: 0.288827\n",
      "Train Epoch: 201 [150/300 (50%)]\tLoss: 0.553597\n",
      "Train Epoch: 201 [160/300 (53%)]\tLoss: 0.364607\n",
      "Train Epoch: 201 [170/300 (57%)]\tLoss: 0.283149\n",
      "Train Epoch: 201 [180/300 (60%)]\tLoss: 0.397124\n",
      "Train Epoch: 201 [190/300 (63%)]\tLoss: 0.310666\n",
      "Train Epoch: 201 [200/300 (67%)]\tLoss: 0.287598\n",
      "Train Epoch: 201 [210/300 (70%)]\tLoss: 0.341242\n",
      "Train Epoch: 201 [220/300 (73%)]\tLoss: 0.074744\n",
      "Train Epoch: 201 [230/300 (77%)]\tLoss: 0.107357\n",
      "Train Epoch: 201 [240/300 (80%)]\tLoss: 0.239092\n",
      "Train Epoch: 201 [250/300 (83%)]\tLoss: 0.245202\n",
      "Train Epoch: 201 [260/300 (87%)]\tLoss: 0.008929\n",
      "Train Epoch: 201 [270/300 (90%)]\tLoss: 0.112887\n",
      "Train Epoch: 201 [280/300 (93%)]\tLoss: 0.188734\n",
      "Train Epoch: 201 [290/300 (97%)]\tLoss: 0.055584\n",
      "Train Epoch: 201 [0/300 (0%)]\tLoss: 0.741474\n",
      "Train Epoch: 201 [10/300 (3%)]\tLoss: 0.114993\n",
      "Train Epoch: 201 [20/300 (7%)]\tLoss: 0.753167\n",
      "Train Epoch: 201 [30/300 (10%)]\tLoss: 0.024750\n",
      "Train Epoch: 201 [40/300 (13%)]\tLoss: 0.071301\n",
      "Train Epoch: 201 [50/300 (17%)]\tLoss: 0.178641\n",
      "Train Epoch: 201 [60/300 (20%)]\tLoss: 0.012467\n",
      "Train Epoch: 201 [70/300 (23%)]\tLoss: 0.146615\n",
      "Train Epoch: 201 [80/300 (27%)]\tLoss: 0.128764\n",
      "Train Epoch: 201 [90/300 (30%)]\tLoss: 0.014041\n",
      "Train Epoch: 201 [100/300 (33%)]\tLoss: 0.235569\n",
      "Train Epoch: 201 [110/300 (37%)]\tLoss: 0.136538\n",
      "Train Epoch: 201 [120/300 (40%)]\tLoss: 0.022210\n",
      "Train Epoch: 201 [130/300 (43%)]\tLoss: 0.054229\n",
      "Train Epoch: 201 [140/300 (47%)]\tLoss: 0.216643\n",
      "Train Epoch: 201 [150/300 (50%)]\tLoss: 0.067274\n",
      "Train Epoch: 201 [160/300 (53%)]\tLoss: 0.146116\n",
      "Train Epoch: 201 [170/300 (57%)]\tLoss: 0.026538\n",
      "Train Epoch: 201 [180/300 (60%)]\tLoss: 0.421580\n",
      "Train Epoch: 201 [190/300 (63%)]\tLoss: 0.119305\n",
      "Train Epoch: 201 [200/300 (67%)]\tLoss: 0.353502\n",
      "Train Epoch: 201 [210/300 (70%)]\tLoss: 0.039380\n",
      "Train Epoch: 201 [220/300 (73%)]\tLoss: 0.101279\n",
      "Train Epoch: 201 [230/300 (77%)]\tLoss: 0.022160\n",
      "Train Epoch: 201 [240/300 (80%)]\tLoss: 0.023192\n",
      "Train Epoch: 201 [250/300 (83%)]\tLoss: 0.093182\n",
      "Train Epoch: 201 [260/300 (87%)]\tLoss: 0.105977\n",
      "Train Epoch: 201 [270/300 (90%)]\tLoss: 0.029318\n",
      "Train Epoch: 201 [280/300 (93%)]\tLoss: 0.134564\n",
      "Train Epoch: 201 [290/300 (97%)]\tLoss: 0.045207\n",
      "Train Epoch: 201 [0/300 (0%)]\tLoss: 0.007180\n",
      "Train Epoch: 201 [10/300 (3%)]\tLoss: 0.225109\n",
      "Train Epoch: 201 [20/300 (7%)]\tLoss: 0.197852\n",
      "Train Epoch: 201 [30/300 (10%)]\tLoss: 0.758945\n",
      "Train Epoch: 201 [40/300 (13%)]\tLoss: 0.233207\n",
      "Train Epoch: 201 [50/300 (17%)]\tLoss: 0.645126\n",
      "Train Epoch: 201 [60/300 (20%)]\tLoss: 0.443736\n",
      "Train Epoch: 201 [70/300 (23%)]\tLoss: 1.100805\n",
      "Train Epoch: 201 [80/300 (27%)]\tLoss: 0.241884\n",
      "Train Epoch: 201 [90/300 (30%)]\tLoss: 0.659257\n",
      "Train Epoch: 201 [100/300 (33%)]\tLoss: 0.289459\n",
      "Train Epoch: 201 [110/300 (37%)]\tLoss: 0.138416\n",
      "Train Epoch: 201 [120/300 (40%)]\tLoss: 0.135942\n",
      "Train Epoch: 201 [130/300 (43%)]\tLoss: 0.256361\n",
      "Train Epoch: 201 [140/300 (47%)]\tLoss: 0.912086\n",
      "Train Epoch: 201 [150/300 (50%)]\tLoss: 0.049374\n",
      "Train Epoch: 201 [160/300 (53%)]\tLoss: 0.111255\n",
      "Train Epoch: 201 [170/300 (57%)]\tLoss: 0.509872\n",
      "Train Epoch: 201 [180/300 (60%)]\tLoss: 0.300072\n",
      "Train Epoch: 201 [190/300 (63%)]\tLoss: 0.300153\n",
      "Train Epoch: 201 [200/300 (67%)]\tLoss: 0.248427\n",
      "Train Epoch: 201 [210/300 (70%)]\tLoss: 0.876286\n",
      "Train Epoch: 201 [220/300 (73%)]\tLoss: 0.016530\n",
      "Train Epoch: 201 [230/300 (77%)]\tLoss: 0.138119\n",
      "Train Epoch: 201 [240/300 (80%)]\tLoss: 0.261600\n",
      "Train Epoch: 201 [250/300 (83%)]\tLoss: 0.082165\n",
      "Train Epoch: 201 [260/300 (87%)]\tLoss: 0.430346\n",
      "Train Epoch: 201 [270/300 (90%)]\tLoss: 0.745284\n",
      "Train Epoch: 201 [280/300 (93%)]\tLoss: 0.438347\n",
      "Train Epoch: 201 [290/300 (97%)]\tLoss: 0.278252\n",
      "Train Epoch: 201 [0/300 (0%)]\tLoss: 0.068529\n",
      "Train Epoch: 201 [10/300 (3%)]\tLoss: 0.053082\n",
      "Train Epoch: 201 [20/300 (7%)]\tLoss: 0.022214\n",
      "Train Epoch: 201 [30/300 (10%)]\tLoss: 0.122818\n",
      "Train Epoch: 201 [40/300 (13%)]\tLoss: 0.036463\n",
      "Train Epoch: 201 [50/300 (17%)]\tLoss: 0.225669\n",
      "Train Epoch: 201 [60/300 (20%)]\tLoss: 0.197838\n",
      "Train Epoch: 201 [70/300 (23%)]\tLoss: 0.032150\n",
      "Train Epoch: 201 [80/300 (27%)]\tLoss: 0.932600\n",
      "Train Epoch: 201 [90/300 (30%)]\tLoss: 0.520568\n",
      "Train Epoch: 201 [100/300 (33%)]\tLoss: 0.526324\n",
      "Train Epoch: 201 [110/300 (37%)]\tLoss: 0.044467\n",
      "Train Epoch: 201 [120/300 (40%)]\tLoss: 0.134101\n",
      "Train Epoch: 201 [130/300 (43%)]\tLoss: 0.015393\n",
      "Train Epoch: 201 [140/300 (47%)]\tLoss: 0.469853\n",
      "Train Epoch: 201 [150/300 (50%)]\tLoss: 0.007552\n",
      "Train Epoch: 201 [160/300 (53%)]\tLoss: 0.063925\n",
      "Train Epoch: 201 [170/300 (57%)]\tLoss: 0.068260\n",
      "Train Epoch: 201 [180/300 (60%)]\tLoss: 0.068070\n",
      "Train Epoch: 201 [190/300 (63%)]\tLoss: 0.057557\n",
      "Train Epoch: 201 [200/300 (67%)]\tLoss: 0.039059\n",
      "Train Epoch: 201 [210/300 (70%)]\tLoss: 0.112194\n",
      "Train Epoch: 201 [220/300 (73%)]\tLoss: 0.041916\n",
      "Train Epoch: 201 [230/300 (77%)]\tLoss: 0.003868\n",
      "Train Epoch: 201 [240/300 (80%)]\tLoss: 0.006056\n",
      "Train Epoch: 201 [250/300 (83%)]\tLoss: 0.290467\n",
      "Train Epoch: 201 [260/300 (87%)]\tLoss: 0.036283\n",
      "Train Epoch: 201 [270/300 (90%)]\tLoss: 0.004577\n",
      "Train Epoch: 201 [280/300 (93%)]\tLoss: 0.143320\n",
      "Train Epoch: 201 [290/300 (97%)]\tLoss: 0.042690\n",
      "Train Epoch: 201 [0/300 (0%)]\tLoss: 0.139300\n",
      "Train Epoch: 201 [10/300 (3%)]\tLoss: 0.035767\n",
      "Train Epoch: 201 [20/300 (7%)]\tLoss: 0.216505\n",
      "Train Epoch: 201 [30/300 (10%)]\tLoss: 0.081550\n",
      "Train Epoch: 201 [40/300 (13%)]\tLoss: 0.333185\n",
      "Train Epoch: 201 [50/300 (17%)]\tLoss: 0.344751\n",
      "Train Epoch: 201 [60/300 (20%)]\tLoss: 0.068682\n",
      "Train Epoch: 201 [70/300 (23%)]\tLoss: 0.465573\n",
      "Train Epoch: 201 [80/300 (27%)]\tLoss: 0.345660\n",
      "Train Epoch: 201 [90/300 (30%)]\tLoss: 0.039611\n",
      "Train Epoch: 201 [100/300 (33%)]\tLoss: 0.154424\n",
      "Train Epoch: 201 [110/300 (37%)]\tLoss: 0.065443\n",
      "Train Epoch: 201 [120/300 (40%)]\tLoss: 0.042808\n",
      "Train Epoch: 201 [130/300 (43%)]\tLoss: 0.063478\n",
      "Train Epoch: 201 [140/300 (47%)]\tLoss: 0.204556\n",
      "Train Epoch: 201 [150/300 (50%)]\tLoss: 0.230830\n",
      "Train Epoch: 201 [160/300 (53%)]\tLoss: 0.161596\n",
      "Train Epoch: 201 [170/300 (57%)]\tLoss: 0.468789\n",
      "Train Epoch: 201 [180/300 (60%)]\tLoss: 0.074087\n",
      "Train Epoch: 201 [190/300 (63%)]\tLoss: 0.282074\n",
      "Train Epoch: 201 [200/300 (67%)]\tLoss: 0.283654\n",
      "Train Epoch: 201 [210/300 (70%)]\tLoss: 0.145791\n",
      "Train Epoch: 201 [220/300 (73%)]\tLoss: 0.002424\n",
      "Train Epoch: 201 [230/300 (77%)]\tLoss: 0.016515\n",
      "Train Epoch: 201 [240/300 (80%)]\tLoss: 0.186464\n",
      "Train Epoch: 201 [250/300 (83%)]\tLoss: 0.075559\n",
      "Train Epoch: 201 [260/300 (87%)]\tLoss: 0.168554\n",
      "Train Epoch: 201 [270/300 (90%)]\tLoss: 0.825089\n",
      "Train Epoch: 201 [280/300 (93%)]\tLoss: 0.467015\n",
      "Train Epoch: 201 [290/300 (97%)]\tLoss: 0.013140\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9778/10000 (98%)\n",
      "\n",
      "Successfully pushed server data to victoria metrics\n",
      "Round 200 finished\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "for num_p_clients in [0, 10, 25, 50, 75, 100, 125, 150, 200]:\n",
    "    client_plane.reset_default_client_nets()\n",
    "    server.reset_to_default_net()\n",
    "    client_plane.reset_poisoning_attack()\n",
    "    config.POISONED_CLIENTS = num_p_clients\n",
    "    update_configs()\n",
    "    client_plane.poison_clients()\n",
    "    clean_idx = select_random_clean()\n",
    "    for i in range(200):\n",
    "        set_rounds(i+1)\n",
    "        run_round(i+1)\n",
    "        if (i+1)%10 == 0:\n",
    "            server.test()\n",
    "            server.push_metrics()\n",
    "        print(\"Round {} finished\".format(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f90fc9a-04e1-4992-a3d2-f028d289aa18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "torch.sum(server.confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e78aed1-4b36-4b4c-bd3f-187006e5e29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "server.get_shap_values()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
